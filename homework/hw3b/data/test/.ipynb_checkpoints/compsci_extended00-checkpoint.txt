AbstractThe Vortex Search Algorithm (VSA) is a single-based meta-heuristic algorithm inspired by the vortices created by stirred fluids. A VSA search creates nested vortices starting from an initial center (the middle of the boundaries), and the vortices are gradually scaled down. In each iteration, the center of a new vortex is created by searching around the previous center and creating a set of candidate solutions with a Gaussian distribution, selecting best of them and comparing it with previous center, in order to replace it. However, this strategy can become trapped in a local optimum, since the search space may not be explored properly by time passing and according to the structure of the many objective functions. Therefore, in this paper an improved version of the VSA is introduced. Actually, the proposed method is not necessarily limited to creating nested vortices; after employing the VSA, the search space is explored by a uniform distribution in each iteration, then the center of the vortex moves toward the best random solution. In this situation, if the shifted center is better than the previous center, then the center is transferred to the new point; in this way, the VSA runs at the shifted center in the next iteration. Therefore, the proposed method is Semi-VSA (SVSA) and its vortices are animated, not necessarily nested. Experiments on 50 benchmark optimization functions indicate that the SVSA is able to improve the VSA, especially when the VSA has been trapped in a local optimum.

Data clustering is a widespread data compression, vector quantization, data analysis, and data mining technique. In this work, a modified form of ABC, i.e. global artificial bee colony search algorithm (GABCS) is applied to data clustering. In GABCS the modification is due to the fact that experienced bees can use past information of quantity of food and position to adjust their movements in a search space. Due to this fact, solution search equations of the canonical ABC are modified in GABCS and applied to three famous real datasets in this work i.e. iris, thyroid, wine, accessed from the UCI database for the purpose of data clustering and results were compared with few other stated algorithms such as K-NM-PSO, TS, ACO, GA, SA and ABC. The results show that while calculating intra-clustering distances and computation time on all three real datasets, the proposed GABCS algorithm gives far better performance than other algorithms whereas calculating computation numbers it performs adequately as compared to typical ABC.
Abstract The symbiotic organism search (SOS) is a recently proposed metaheuristic optimization algorithm that simulates the symbiotic interaction strategies adopted by organisms to survive and propagate in an ecosystem. Clustering is a popular data analysis and data mining technique, and k-means clustering is one of the most commonly used methods. However, its effectiveness is highly dependent on the initial solution, and the algorithm may become trapped around local optima. In view of these drawbacks of the k-means method, this paper describes the use of the SOS algorithm to solve clustering problems. Ten standard datasets from the UCI Machine Learning Repository are used to evaluate the effectiveness of SOS against that of optimization algorithms including differential evolution, cuckoo search, flower pollination, particle swarm optimization, artificial bee colony, multi-verse optimizer, and k-means. Experimental results show that the SOS algorithm not only achieves superior accuracy, but also exhibits a higher level of stability.
In peer to peer (P2P) video streaming systems, peers in network assist to forward the data to other peers without the interference of central servers. Video on Demand (VoD) is widely using internet service, which offers video to users with effective control when they need it. The major significant problem in developing a P2P VoD system is data scheduling, which concentrates on dealing with transmitting and dispatching data segments within a system efficiently. So a Gravitational Search Algorithm based data Scheduling (GSAS) is presented in this paper. Initially, the network is developed in the form of hierarchical topology. Video file is cached as data segments in each peer in the top layer of the network. Using the priority function, these data segments are sorted or prioritized. Using the proposed GSA algorithm, optimal or suitable peers which cache the requested data segments in the top layer are selected. Then the prioritized data segments from the selected peers are scheduled to the peer which has requested for video sequences. The video file “Grandmother” with the size 53 MB is examined in this approach. This proposed approach is simulated in the network simulator. Simulation results show that the performance of this proposed approach is superior to that of the existing work in terms of throughput and scheduling time.
This paper proposes a novel approach that selects the number of clusters along with relevant features automatically and simultaneously. Gravitational search algorithm is used as metaheuristic. A novel agent representation scheme is used for encoding cluster centers and number of features. The algorithm is able to find the optimal number of clusters and the relevant features corresponding to the clusters during the run time. A new concept of threshold setting is used. The variance (statistical property) of the dataset has been exploited. To make the search efficient, a novel clustering criterion is used. The proposed approach is compared with recently developed well-known clustering techniques. This approach is further applied for analysis of microarray data. The statistical and biological significance tests are performed to demonstrate the efficiency of proposed approach. The results prove the effectiveness and the accuracy of the proposed algorithm.
Clustering is an unsupervised classification method used to group the objects of an unlabeled data set. The high dimensional data sets generally comprise of irrelevant and redundant features also along with the relevant features which deteriorate the clustering result. Therefore, feature selection is necessary to select a subset of relevant features as it improves discrimination ability of the original set of features which helps in improving the clustering result. Though many metaheuristics have been suggested to select subset of the relevant features in wrapper framework based on some criteria, most of them are marred by the three key issues. First, they require objects class information a priori which is unknown in unsupervised feature selection. Second, feature subset selection is devised on a single validity measure; hence, it produces a single best solution biased toward the cardinality of the feature subset. Third, they find difficulty in avoiding local optima owing to lack of balancing in exploration and exploitation in the feature search space. To deal with the first issue, we use unsupervised feature selection method where no class information is required. To address the second issue, we follow pareto-based approach to obtain diverse trade-off solutions by optimizing conceptually contradicting validity measures silhouette index (Sil) and feature cardinality (d). For the third issue, we introduce genetic crossover operator to improve diversity in a recent Newtonian law of gravity-based metaheuristic binary gravitational search algorithm (BGSA) in multi-objective optimization scenario; it is named as improved multi-objective BGSA for feature selection (IMBGSAFS). We use ten real-world data sets for comparison of the IMBGSAFS results with three multi-objective methods MBGSA, MOPSO, and NSGA-II in wrapper framework and the Pearson’s linear correlation coefficient (FM-CC) as a multi-objective filter method. We employ four multi-objective quality measures convergence, diversity, coverage and ONVG. The obtained results show superiority of the IMBGSAFS over its competitors. An external clustering validity index F-measure also establish the above finding. As the decision maker picks only a single solution from the set of trade-off solutions, we employee the F-measure to select a final single solution from the external archive. The quality of final solution achieved by IMBGSAFS is superior over competitors in terms of clustering accuracy and/or smaller subset size.
The presence of imbalance in data significantly complicates the classification task, including fuzzy systems. Due to a large number of instances of bigger classes, instances of smaller classes are not recognized correctly. Therefore, additional tools for improving the quality of classification are required. The most common methods for handling imbalanced data have several disadvantages. For example, methods for generating additional instances of minority classes can worsen classification if there is a strong overlap of instances from different classes. Methods that directly modify the fuzzy classification algorithm lead to a decline in the interpretability of the model. In this paper, we study the efficiency of the gravitational search algorithm in the tasks of selecting the features and tuning the term parameters for fuzzy classifiers of imbalanced data. We consider only data with two classes and apply the algorithm based on extreme values of classes to construct models with a minimum number of rules. In addition, we propose a new quality metric based on the sum of the overall accuracy and the geometric mean with the presence of a priority coefficient between them.
Aiming at the shortcomings of current methods of bad data detection and identification in a power system, this article advances a new method to identify bad data of the power system based on the enhanced gravitation search-fuzzy c-mean algorithm (EGSA-FCM). By using the enhanced gravity search algorithm (EGSA), a better initial solution to search the measurement data uploaded by SCADA system is obtained. Then, the FCM algorithm was used to obtain the classification of benign data and bad data. Finally, through the COS clustering validity judgment index, the optimal clustering number is determined and the optimal clustering results and bad data were obtained. This method has already been applied to the IEEE 14-node power system and a regional power grid in Daqing, China. The results indicated that the proposed method is more accurate than the traditional ones and effectively avoid the occurrence of false detection and missed detection.
As known, the artificial bee colony (ABC) algorithm is an optimization algorithm based on the intelligent foraging behavior of honey bee swarm that has been proven its efficacy and successfully applied to a large number of practical problems. Aiming at the trade-off between convergence speed and precocity of ABC algorithm with elite-guided search equations (ABC_elite), an enhanced version, namely EABC_elite, is proposed in this paper, and the improvements are twofold. As the global best (gbest) solution is introduced to the search equation and acceleration of the convergence in the bee phase of EABC_elite, the former in the ordinary solution is embodied to the search equation yet balance the gbest’s ability. The enhancement to the global search by making the information of gbest and ordinary solutions be adequately used while keeping the exploration–exploitation balance well maintained, the usual solution is introduced to the search equation to avoid the precocity problem in the onlooker bee phase of EABC_elite as the latter one. Experimental analysis and evaluations of EABC_elite against several state-of-the-art variants of the ABC algorithm demonstrate that the EABC_elite is significantly better than the compared algorithms in the feature selection problem. Also, the proposed EABC_elite algorithm is modified to combine the K-means initialization strategy and chaotic parameters strategy to further enhance the global search of EABC_elite for data clustering. Experimental results show that the derived EABC_elite clustering algorithm “Two-step EABC_elite,” TEABC_elite for short, delivered better and promising results than previous works for data clustering.
Automatic clustering based hybrid metaheuristic algorithms has attracted the center of interest of scientists and engineers which become a hot topic for different data analysis applications. For example, image clustering, bioinformatics, image segmentation, and natural language processing. Where the process of determining the number and position of centroids is an NP-hard problem. So, this paper presents an alternative automatic clustering algorithm based on the hybrid between the atom search optimization (ASO) and the sine-cosine algorithm (SCA). The main objective of the proposed clustering method, called ASOSCA, is to find automatically the optimal number of centroids and their positions in order to minimize the CS-index (which refers to Compact-separated index). To achieve this goal, the ASOSCA uses SCA as a local search operator to improve the quality of ASO. The performance of the proposed hybrid method is compared with other metaheuristic methods; in which all of them are tested on sixteen clustering datasets and using different cluster validity indexes as Dunn, Silihouette, Davies Bouldin, and Calinski Harabasz. The experimental results show that the ASOSCA depict high superiority in comparison with other types of hybrid metaheuristic in terms of clustering measures.
Motif discovery is the problem of finding common substrings in a set of biological strings. Therefore, it can be applied to find Transcription Factors Binding Sites (TFBS) that have common patterns (motifs). The Quorum Planted $(l,\ d,\ q)$ Motif Search (qPMS) is a version of Planted $(l,\ d)$ motif discovery where the motif of length l occurs in at least q percent of the sequences with up to d mismatches. The recent introduction of technologies such as ChIP (chromatin immunoprecipitation) experiments poses further challenges for algorithm developers, as the outputs of such experiments contain thousands of sequences. ChIP-Seq (ChIP sequencing, to analyze protein interactions with DNA) has gained considerable attention in the field.The focus of this paper is to present an approximate algorithm, quorum Strong Motif Finder (qSMF) that returns up to k highest ranked (strongest) motifs in at least q percent of the data sequences. The proposed algorithm has been tested on ChIP-Seq (large) data that was sampled using the SamSelect algorithm. In comparisons with the FMotif algorithm, the experimental results show that qSMF is faster and returns predicted motifs similar to published ones in the literature and to motifs discovered by a tool that uses the established motif finding algorithms of AlignACE, MEME, MDscan, Trawler, and Weeder.
Keyword search tools have been used to query RDF data. They can be labeled as schema-based when the RDF schema is used to compile a keyword-based query into a SPARQL query, or graph-based when the RDF dataset is directly traveled or summarized. The approach proposed in the thesis belongs to this latter category. Unlike recent approaches that summarize the RDF graph, the proposed approach explores the similarity between the property domains and ranges and the class instance sets present in the RDF dataset. The approach estimates set similarity using the Jaccard and the set containment measures. To achieve good performance, even for large RDF datasets, the similarity measures are estimated based on k-Minimum hash Values (KMV) synopses [3]. This paper presents the research methodology to implement a keyword search algorithm over large RDF graphs, which does not rely on schema information and uses KMV-synopses. However, the use of KMV-synopses introduces new challenges. So, the research includes the implementation of strategies to efficiently compute KMV-synopses for large RDF datasets and to keep them synchronized when the RDF dataset is up-dated, avoiding full re-computation of the synopses. Finally, the paper presents the status of the research, the open issues and the roadmap to address them.
With the rapid development of biotechnology, researchers are able to obtain large number of genome data sets. However, biological data often involves high privacy and data security issues. Thus when storing, transferring or analyzing these data, a safe and effective method is highly needed. This paper aims to propose a practical scheme using searchable homomorphic encryption. We combined the inverted index mechanism with the interactive operation on the homomorphic encrypted ciphertext data files, so as to realize the management and protection of biological data.
Database encryption is a process in which the data stored in the database are converted from plaintext (PT) to ciphertext (CT). The original data can be retrieved from the ciphertext with the help of a predefined key and a decryption scheme. This way, only the appropriate authority that has the key can access the data. Thus, encrypted databases help ensure data confidentiality and avoid data leaks. In this paper, we will describe a modification to the Secure K-Nearest Neighbours (SkNN) [3] technique to construct an encrypted database system. We briefly discuss some of the existing encryption models and the principles involved in their construction and look at some of the issues that plague these models. The motivation behind this paper is to devise a method that allows for strong database encryption, while at the same time facilitating efficient search over the encrypted data. In order to achieve this, we suggest an approach which combines RSA with the SkNN scheme.
Data clustering is a significant and strong data analysis technique which has a broad range of applications in many domains. In this paper, the artificial bee colony algorithm (ABC) is adopted to partition data sets into K clusters. To trade off the global and local searching ability of ABC algorithm, two kinds of cooperative search based ABC algorithms are proposed, that is N2ABC and WCABC. Then, the proposed algorithms are combined with K-means to deal with data clustering. For the purpose of demonstrating the efficiency of two hybrid clustering algorithms (N2ABCC and WCABCC), one artificial data set and six benchmark data sets are selected to test clustering results. Meanwhile, five algorithms, namely K-means, PSOC, ABCC, GABCC and CABCC, are chosen for comparison. The clustering results indicate that the proposed algorithms have better clustering validity than other algorithms.
Biofarma Corp should adopt big data on vaccine and serum development by analyze genomic sequencing using searching any anomaly. As the root problem, it the anomaly searching requires about 1.62 Terabytes data transient as primary data and 301 Gigabytes as secondary data to get analysis from genomic variance. Moreover Biofarma Corp spent 16 hours for one anomaly searching from 3 Terabytes vaccines. This study proposed big data implementation to handle anomaly searching processes by prioritize less time complexity and less spending storage. It was signalized by a research question, “How big data technology is applied in searching anomalies on genomic data”. It aimed to implement big data system to facilitate large volume and complex data in order to fulfill business process on Biofarma Corp. It adopted framework architecture as brought by Demchenko, Ngo, and Membrey. This study has designed data flow from FASTA and FATQ as sources for anomalies searching processes. This data flow is facilitated in big data system as designed in this research. As main contribution, this research adopted MapReduce framework to run BLAST algorithm with less spending time. As comparison, MapReduce framework can handle 21, 33, and 55 K-Mer in four minutes respectively while 50 minutes were spent without MapReduce.
This article consides visual search system for conventions detection in images collection. System contains k-means clusterisation and key points based method. This article consides existing methods comparison of visual search and their software implementation
In recent years, how to discover the valuable knowledge from a huge amount of data has been a hot topic. Data mining is one of the solutions for this topic. Actually, data mining has been studied for a long time, including a lot of paradigms. Among these paradigms, High-Utility Itemset Mining attracts much research attention because it can find the itemsets different from traditional frequent itemsets. Although these related works have been shown to be efficient, it still cannot mine the really rare itemsets infrequent by only one minimum utility support. In addition, an efficient mining algorithm relies on an important factor “search strategy”. For these concerns, in this paper, an efficient high-utility itemset mining algorithm with multiple minimum utility support and prefix-search strategy is proposed to effectively mine the really valuable itemsets. For effectiveness, the rare but infrequent itemsets can be discovered by the individually specified utility supports. For efficiency, the aimed itemsets can be mined without the level-wise searching by a prefix-search way. The experimental results show the proposed algorithm performs better than the compared one on the synthetic and real datasets.
Beetle Antennae Search (BAS) is a newly developed nature-inspired algorithm, which falls in the class of single-solution driven metaheuristic techniques. This algorithm mimics the searching behavior of the longhorn beetles for food or potential mate using their long antennae. This algorithm is potentially effective in achieving global best solutions promptly. An attempt is made in this paper to implement the data-driven BAS, which exploits the Cascade Feed-Forward Neural Network (CFNN) training for functional approximation. The proposed technique is utilized to model the electrical power output of a Combined Cycle Power Plant (CCPP). The power output of a power plant could be dependent on four input parameters, such as Ambient Temperature (AT), Exhaust Vacuum (V), Atmospheric Pressure (AP), and Relative Humidity (RH). These parameters affect the electrical power output, which is considered as the target variable. The CFNN based predictive model is shown to perform equivalently while compared with published machine learning based regression methods. The proposed data-driven BAS algorithm is effective in producing optimal electric power output for the CCPP.
