Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction. These systems, especially the k-nearest neighbor collaborative ltering based ones, are achieving widespread success on the Web. The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity. In traditional collaborative ltering systems the amount of work increases with the number of participants in the system. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very large-scale problems. To address these issues we have explored item-based collaborative ltering techniques. Item-based techniques rst analyze the user-item matrix to identify relationships between di erent items, and then use these relationships to indirectly compute recommendations for users. In this paper we analyze di erent item-based recommendation generation algorithms. We look into di erent techniques for computing item-item similarities (e.g., item-item correlation vs. cosine similarities between item vectors) and di erent techniques for obtaining recommendations from them (e.g., weighted sum vs. regression model). Finally, we experimentally evaluate our results and compare them to the basic k-nearest neighbor approach. Our experiments suggest that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available userbased algorithms.
Abstract With the widespread diffusion of Massive Online Open Courses (MOOCs), educational recommender systems have become central tools to support students in their learning process. While most of the literature has focused on students and the learning opportunities that are offered to them, the teachers behind the recommended courses get a certain exposure when they appear in the final ranking. Underexposed teachers might have reduced opportunities to offer their services, so accounting for this perspective is of central importance to generate equity in the recommendation process. In this paper, we consider groups of teachers based on their geographic provenience and assess provider (un)fairness based on the continent they belong to. We consider measures of visibility and exposure, to account ( i ) in how many recommendations and ( i i ) wherein the ranking of the teachers belonging to different groups appear. We observe disparities that favor the most represented groups, and we overcome these phenomena with a re-ranking approach that provides each group with the expected visibility and exposure, thus controlling fairness of providers coming from different continents (cross-continent provider fairness). Experiments performed on data coming from a real-world MOOC platform show that our approach can provide fairness without affecting recommendation effectiveness.

 The popularity of social media platforms results in a huge volume of online conversations produced every day. To help users better engage in online conversations, this article presents a novel framework to automatically recommend conversations to users based on what they said and how they behaved in their chatting histories. While prior work mostly focuses on post-level recommendation, we aim to explore conversation context and model the interaction patterns therein. Furthermore, to characterize personal interests from interleaving user interactions, we learn (1)
 global interactions
 , represented by topic and discourse word clusters to reflect users’ content and pragmatic preferences, and (2)
 local interactions
 , encoding replying relations and chronological order of conversation turns to characterize users’ prior behavior. Built on collaborative filtering, our model captures global interactions via discovering word distributions to represent users’ topical interests and discourse behaviors, while local interactions are explored with graph-structured networks exploiting both reply structure and temporal features. Extensive experiments on three datasets from Twitter and Reddit show that our model coupling global and local interactions significantly outperforms the state-of-the-art model. Further analyses show that our model is able to capture meaningful features from global and local interactions, which results in its superior performance in conversation recommendation.


 For present e-commerce platforms, it is important to accurately predict users’ preference for a timely next-item recommendation. To achieve this goal, session-based recommender systems are developed, which are based on a sequence of the most recent user-item interactions to avoid the influence raised from outdated historical records. Although a session can usually reflect a user’s current preference, a local shift of the user’s intention within the session may still exist. Specifically, the interactions that take place in the early positions within a session generally indicate the user’s initial intention, while later interactions are more likely to represent the latest intention. Such positional information has been rarely considered in existing methods, which restricts their ability to capture the significance of interactions at different positions. To thoroughly exploit the positional information within a session, a theoretical framework is developed in this paper to provide an in-depth analysis of the positional information. We formally define the properties of
 forward-awareness
 and
 backward-awareness
 to evaluate the ability of positional encoding schemes in capturing the initial and the latest intention. According to our analysis, existing positional encoding schemes are generally
 forward-aware
 only, which can hardly represent the dynamics of the intention in a session. To enhance the positional encoding scheme for the session-based recommendation, a dual positional encoding (DPE) is proposed to account for both
 forward-awareness
 and
 backward-awareness
 . Based on DPE, we propose a novel Positional Recommender (PosRec) model with a well-designed Position-aware Gated Graph Neural Network module to fully exploit the positional information for session-based recommendation tasks. Extensive experiments are conducted on two e-commerce benchmark datasets,
 Yoochoose
 and
 Diginetica
 and the experimental results show the superiority of the PosRec by comparing it with the state-of-the-art session-based recommender models.

It is common practice for many large e-commerce operators to analyze daily logged transaction data to predict customer purchase behavior, which may potentially lead to more effective recommendation...
Social recommendation has achieved great success in many domains including e-commerce and location-based social networks. Existing methods usually explore the user-item interactions or user-user connections to predict users’ preference behaviors. However, they usually learn both user and item representations in Euclidean space, which has large limitations for exploring the latent hierarchical property in the data. In this article, we study a novel problem of hyperbolic social recommendation, where we aim to learn the compact but strong representations for both users and items. Meanwhile, this work also addresses two critical domain-issues, which are under-explored. First, users often make trade-offs with multiple underlying aspect factors to make decisions during their interactions with items. Second, users generally build connections with others in terms of different aspects, which produces different influences with aspects in social network. To this end, we propose a novel graph neural network (GNN) framework with multiple aspect learning, namely, HyperSoRec. Specifically, we first embed all users, items, and aspects into hyperbolic space with superior representations to ensure their hierarchical properties. Then, we adapt a GNN with novel multi-aspect message-passing-receiving mechanism to capture different influences among users. Next, to characterize the multi-aspect interactions of users on items, we propose an adaptive hyperbolic metric learning method by introducing learnable interactive relations among different aspects. Finally, we utilize the hyperbolic translational distance to measure the plausibility in each user-item pair for recommendation. Experimental results on two public datasets clearly demonstrate that our HyperSoRec not only achieves significant improvement for recommendation performance but also shows better representation ability in hyperbolic space with strong robustness and reliability.

 Reducing the shortage of organ donations to meet the demands of patients on the waiting list has being a major challenge in organ transplantation. Because of the shortage, organ matching decision is the most critical decision to assign the limited viable organs to the most “suitable” patients. Currently, organ matching decisions are only made by matching scores calculated via scoring models, which are built by the first principles. However, these models may disagree with the actual post-transplantation matching performance (e.g., patient's post-transplant
 quality of life (QoL)
 or graft failure measurements). In this paper, we formulate the organ matching decision-making as a top-N recommendation problem and propose an
 Adaptively Weighted Top-N Recommendation (AWTR)
 method. AWTR improves performance of the current scoring models by using limited actual matching performance in historical datasets as well as the collected covariates from organ donors and patients. AWTR sacrifices the overall recommendation accuracy by emphasizing the recommendation and ranking accuracy for top-N matched patients. The proposed method is validated in a simulation study, where KAS [
 60
 ] is used to simulate the organ-patient recommendation response. The results show that our proposed method outperforms seven state-of-the-art top-N recommendation benchmark methods.


 Sequential recommenders capture dynamic aspects of users’ interests by modeling sequential behavior. Previous studies on sequential recommendations mostly aim to identify users’ main recent interests to optimize the recommendation accuracy; they often neglect the fact that users display multiple interests over extended periods of time, which could be used to improve the diversity of lists of recommended items. Existing work related to diversified recommendation typically assumes that users’ preferences are static and depend on post-processing the candidate list of recommended items. However, those conditions are not suitable when applied to sequential recommendations. We tackle sequential recommendation as a list generation process and propose a unified approach to take accuracy as well as diversity into consideration, called
 multi-interest, diversified, sequential recommendation
 . Particularly, an implicit interest mining module is first used to mine users’ multiple interests, which are reflected in users’ sequential behavior. Then an interest-aware, diversity promoting decoder is designed to produce recommendations that cover those interests. For training, we introduce an interest-aware, diversity promoting loss function that can supervise the model to learn to recommend accurate as well as diversified items. We conduct comprehensive experiments on four public datasets and the results show that our proposal outperforms state-of-the-art methods regarding diversity while producing comparable or better accuracy for sequential recommendation.

Next-Generation Radio Access Network (NG-RAN) is an emerging paradigm that provides flexible distribution of cloud computing and radio capabilities at the edge of the wireless Radio Access Points (RAPs). Computation at the edge bridges the gap for roaming end users, enabling access to rich services and applications. In this paper, we propose a multi-edge node task offloading system, i.e., QLRan, a novel optimization solution for latency and quality tradeoff task allocation in NG-RANs. Considering constraints on service latency, quality loss, and edge capacity, the problem of joint task offloading, latency, and Quality Loss of Result (QLR) is formulated in order to minimize the User Equipment (UEs) task offloading utility, which is measured by a weighted sum of reductions in task completion time and QLR cost. The QLRan optimization problem is proved as a Mixed Integer Nonlinear Program (MINLP) problem, which is a NP-hard problem. To efficiently solve the QLRan optimization problem, we utilize Linear Programming (LP)-based approach that can be later solved by using convex optimization techniques. Additionally, a programmable NG-RAN testbed is presented where the Central Unit (CU), Distributed Unit (DU), and UE are virtualized using the OpenAirInterface (OAI) software platform to characterize the performance in terms of data input, memory usage, and average processing time with respect to QLR levels. Simulation results show that our algorithm performs significantly improves the network latency over different conflgurations.
With the increasing scale and diversification of interaction behaviors in E-commerce, more and more researchers pay attention to multi-behavior recommender systems which utilize interaction data of other auxiliary behaviors. However, all existing models ignore two kinds of intrinsic heterogeneity which are helpful to capture the difference of user preferences and the difference of item attributes. First (intra-heterogeneity), each user has multiple social identities with otherness, and these different identities can result in quite different interaction preferences. Second (inter-heterogeneity), each item can transfer an item-specific percentage of score from low-level behavior to high-level behavior for the gradual relationship among multiple behaviors. Thus, the lack of consideration of these heterogeneities damages recommendation rank performance. To model the above heterogeneities, we propose a novel method named intrA- and inteR-heteroGeneity recOmmendation model (ARGO). Specifically, we embed each user into multiple vectors representing the user's identities, and the maximum of identity scores indicates the interaction preference. Besides, we regard the item-specific transition percentage as trainable transition probability between different behaviors. Extensive experiments on two real-world datasets show that ARGO performs much better than the state-of-the-art in multi-behavior scenarios.
Onsite retargeting is a type of targeting and product recommendation strategy typically offered on the homepage of online retailers based on customers’ prior behavior on retailers’ own websites. Onsite retargeting consists of a retargeted product that consumers previously interacted with and the recommendations based on the retargeted product. While onsite retargeting presents a fertile opportunity to address customers in a personalized manner, little is known about how its effectiveness varies depending on the choice of the retargeted product and how customers respond to the retargeted versus recommended products. In collaboration with a leading online retailer, we collected data from a large-scale randomized field experiment to examine the effectiveness of wishlist-based retargeting (retargeting based on products in consumer’s wishlist) compared to commonly used view-based retargeting (retargeting based on viewed products). Our empirical results suggest that wishlist-based retargeting is more effective than view-based retargeting in generating clicks and conversions for the retargeted (source) products. However, the incremental effectiveness of wishlist-based retargeting declines for recommended products. In addition, we find that onsite retargeting loses effectiveness as time passes, but this negative timing effect is smaller for wishlist-based retargeting than view-based retargeting. We further conduct an online experiment that replicates the findings of the field experiment and explores the mechanisms underlying the observed behaviors. This work contributes to the retargeting and personalized recommendations literature and provides meaningful implications for practitioners.
The promise of quantum computing to open new unexplored possibilities in several scientific fields has been long discussed, but until recently the lack of a functional quantum computer has confined this discussion mostly to theoretical algorithmic papers. It was only in the last few years that small but functional quantum computers have become available to the broader research community. One paradigm in particular, quantum annealing, can be used to sample optimal solutions for a number of NP-hard optimization problems represented with classical operations research tools, providing an easy access to the potential of this emerging technology. One of the tasks that most naturally fits in this mathematical formulation is feature selection. In this paper, we investigate how to design a hybrid feature selection algorithm for recommender systems that leverages the domain knowledge and behavior hidden in the user interactions data. We represent the feature selection as an optimization problem and solve it on a real quantum computer, provided by D-Wave. The results indicate that the proposed approach is effective in selecting a limited set of important features and that quantum computers are becoming powerful enough to enter the wider realm of applied science.
Abstract Personalized recommendation is a popular research direction in both industry and academia. Some research on recommender systems utilizes the users’ interaction history on items to represent the users’ interests, which has achieved remarkable success. Users’ interests in the real world are dynamically changing and have a strong correlation with the interaction sequence. However, sometimes users’ interests are less relevant to the order of the current interaction sequence, but are more relevant to certain items in the user interaction history. In this paper, a novel deep neural network model is proposed to deal with this situation. The developed model consists of two parts: the present interest relevant to the order of the interaction sequence and the comprehensive interest relevant to some items in the interaction sequence. An ancillary multi-layer perceptron (MLP) is constructed to improve the training of our model. Experiments on public and industrial datasets are conducted. The experimental results show that our proposed model outperforms the state-of-the-art models which demonstrates the effectiveness of the ancillary MLP.
Human behaviors in recommendation systems are driven by many high-level, complex, and evolving intentions behind their decision making processes. In order to achieve better performance, it is important for recommendation systems to be aware of user intentions besides considering the historical interaction behaviors. However, user intentions are seldom fully or easily observed in practice, so that the existing works are incapable of fully tracking and modeling user intentions, not to mention using them effectively into recommendation. In this paper, we present the Intention-Aware Sequential Recommendation (ISRec) method, for capturing the underlying intentions of each user that may lead to her next consumption behavior and improving recommendation performance. Specifically, we first extract the intentions of the target user from sequential contexts, then take complex intent transition into account through the message-passing mechanism on an intention graph, and finally obtain the future intentions of this target user from inference on the intention graph. The sequential recommendation for a user will be made based on the predicted user intentions, offering more transparent and explainable intermediate results for each recommendation. Extensive experiments on various real-world datasets demonstrate the superiority of our method against several state-of-the-art baselines in sequential recommendation in terms of different metrics.
Recent advances in path-based explainable recommendation systems have attracted increasing attention thanks to the rich information provided by knowledge graphs. Most existing explainable recommendation only utilizes static knowledge graph and ignores the dynamic user-item evolutions, leading to less convincing and inaccurate explanations. Although there are some works that realize that modelling user's temporal sequential behaviour could boost the performance and explainability of the recommender systems, most of them either only focus on modelling user's sequential interactions within a path or independently and separately of the recommendation mechanism. In this paper, we propose a novel Temporal Meta-path Guided Explainable Recommendation (TMER), which utilizes well-designed item-item path modelling between consecutive items with attention mechanisms to sequentially model dynamic user-item evolutions on dynamic knowledge graph for explainable recommendations. Compared with existing works that use heavy recurrent neural networks to model temporal information, we propose simple but effective neural networks to capture users' historical item features and path-based context to characterise next purchased item. Extensive evaluations of TMER on three real-world benchmark datasets show state-of-the-art performance compared against recent strong baselines.
One common characteristic of research works focused on fairness evaluation (in machine learning) is that they call for some form of parity (equality) either in treatment—meaning they ignore the information about users’ memberships in protected classes during training—or in impact—by enforcing proportional beneficial outcomes to users in different protected classes. In the recommender systems community, fairness has been studied with respect to both users’ and items’ memberships in protected classes defined by some sensitive attributes (e.g., gender or race for users, revenue in a multi-stakeholder setting for items). Again here, the concept has been commonly interpreted as some form of equality—i.e., the degree to which the system is meeting the information needs of all its users in an equal sense. In this work, we propose a probabilistic framework based on generalized cross entropy (GCE) to measure fairness of a given recommendation model. The framework comes with a suite of advantages: first, it allows the system designer to define and measure fairness for both users and items and can be applied to any classification task; second, it can incorporate various notions of fairness as it does not rely on specific and predefined probability distributions and they can be defined at design time; finally, in its design it uses a gain factor, which can be flexibly defined to contemplate different accuracy-related metrics to measure fairness upon decision-support metrics (e.g., precision, recall) or rank-based measures (e.g., NDCG, MAP). An experimental evaluation on four real-world datasets shows the nuances captured by our proposed metric regarding fairness on different user and item attributes, where nearest-neighbor recommenders tend to obtain good results under equality constraints. We observed that when the users are clustered based on both their interaction with the system and other sensitive attributes, such as age or gender, algorithms with similar performance values get different behaviors with respect to user fairness due to the different way they process data for each user cluster.
Abstract Collaborative filtering has been the most straightforward and most preferable approach in the recommender systems. This technique recommends an item to a target user from the preferences of top-k similar neighbors. In a sparse data scenario, the recommendation accuracy of the collaborative filtering degrades significantly due to the limitations of existing various similarity measures. Such constraints offer an open scope for enhancing the accuracy of optimized user-specific recommendations. Many techniques have been utilized for this, like Particle Swarm Optimization and other evolutionary collaborative filtering algorithms. The proposed approach utilizes the Apriori algorithm to form users’ profiles from the items’ ratings and categorical attributes. The user profile creation is performed using the apriori algorithm. The profile of each user involves the likes and disliking of categorical characteristics of objects by users. In the collected MovieLens dataset, the efficiency of the proposed recommendation approach is tested. The comparative results show proof that the proposed novel algorithm outperforms other prominent collaborative filtering algorithms on the MovieLens datasets based on rating prediction accuracy.
Recently, recommender systems play a pivotal role in alleviating the problem of information overload. Latent factor models have been widely used for recommendation. Most existing latent factor models mainly utilize the interaction information between users and items, although some recently extended models utilize some auxiliary information to learn a unified latent factor for users and items. The unified latent factor only represents the characteristics of users and the properties of items from the aspect of purchase history. However, the characteristics of users and the properties of items may stem from different aspects, e.g., the brand-aspect and category-aspect of items. Moreover, the latent factor models usually use the shallow projection, which cannot capture the characteristics of users and items well. Deep neural network has shown tremendous potential to model the non-linearity relationship between users and items. It can be used to replace shallow projection to model the complex correlation between users and items. In this paper, we propose a Neural network based Aspect-level Collaborative Filtering model (NeuACF) to exploit different aspect latent factors. Through modelling the rich object properties and relations in recommender system as a heterogeneous information network, NeuACF first extracts different aspect-level similarity matrices of users and items, respectively, through different meta-paths, and then feeds an elaborately designed deep neural network with these matrices to learn aspect-level latent factors. Finally, the aspect-level latent factors are fused for the top-N recommendation. Moreover, to fuse information from different aspects more effectively, we further propose NeuACF++ to fuse aspect-level latent factors with self-attention mechanism. Extensive experiments on three real world datasets show that NeuACF and NeuACF++ significantly outperform both existing latent factor models and recent neural network models.
Due to privacy concerns, there is a rising favor in Recommender System community for the One-class Collaborative Filtering (OCCF) framework, which predicts user preferences only based on binary implicit feedback (e.g., click or not-click, rated or unrated). The major challenge in OCCF problem stems from the inherent noise in implicit interaction. Previous approaches have taken into account the noise in unobserved interactions (i.e., not-click only means a missing value, rather than negative feedback). However, they generally ignore the noise in observed interactions (i.e., click does not necessarily represent positive feedback), which might induce performance degradation. To attack this issue, we propose a novel iteratively relabeling framework to jointly mitigate the noise in both observed and unobserved interactions. As the core of the framework, the iterative relabeling module exploits the self-training principle to dynamically generate pseudo labels for user preferences. The downstream module for a recommendation task is then trained with the refreshed labels where the noisy patterns are largely alleviated. Finally, extensive experiments on three real-world datasets demonstrate the effectiveness of our proposed methods.
Recent advancements of sequential deep learning models such as Transformer and BERT have significantly facilitated the sequential recommendation. However, according to our study, the distribution of item embeddings generated by these models tends to degenerate into an anisotropic shape, which may result in high semantic similarities among embeddings. In this paper, both empirical and theoretical investigations of this representation degeneration problem are first provided, based on which a novel recommender model DuoRec is proposed to improve the item embeddings distribution. Specifically, in light of the uniformity property of contrastive learning, a contrastive regularization is designed for DuoRec to reshape the distribution of sequence representations. Given the convention that the recommendation task is performed by measuring the similarity between sequence representations and item embeddings in the same space via dot product, the regularization can be implicitly applied to the item embedding distribution. Existing contrastive learning methods mainly rely on data level augmentation for useritem interaction sequences through item cropping, masking, or reordering and can hardly provide semantically consistent augmentation samples. In DuoRec, a model-level augmentation is proposed based on Dropout to enable better semantic preserving. Furthermore, a novel sampling strategy is developed, where sequences having the same target item are chosen hard positive samples. Extensive experiments conducted on five datasets demonstrate the superior performance of the proposed DuoRec model compared with baseline methods. Visualization results of the learned representations validate that DuoRec can largely alleviate the representation degeneration problem.
Users of recommendation systems usually focus on one topic at a time. When finishing reading an item, users may want to access more relevant items related to the last read one as extended reading. However, conventional recommendation systems are hard to provide the continuous extended reading function of these relevant items, since the main recommendation results should be diversified. In this paper, we propose a new task named recommendation suggestion, which aims to (1) predict whether users want extended reading, and (2) provide appropriate relevant items as suggestions. These recommended relevant items are arranged in a relevant box and instantly inserted below the clicked item in the main feed. The challenge of recommendation suggestion on relevant items is that it should further consider semantic relevance and information gain besides CTR-related factors. Moreover, the real-time relevant box insertion may also harm the overall performance when users do not want extended reading. To address these issues, we propose a novel Real-time relevant recommendation suggestion (R3S) framework, which consists of an Item recommender and a Box trigger. We extract features from multiple aspects including feature interaction, semantic similarity and information gain as different experts, and propose a new Multi-critic multi-gate mixture-of-experts (M3oE) strategy to jointly consider different experts with multi-head critics. In experiments, we conduct both offline and online evaluations on a real-world recommendation system with detailed ablation tests. The significant improvements in item/box related metrics verify the effectiveness of R3S. Moreover, we have deployed R3S on WeChat Top Stories, which affects millions of users. The source codes are in https://github.com/modriczhang/R3S.
With an increase in online longitudinal users’ interactions, capturing users’ precise preferences and giving accurate recommendations have become an urgent need for all businesses. Existing sequence-aware methods generally exploit a static low-rank vector for acquiring the overall sequential features, and incorporate context information as auxiliary input. As a result, they have a restricted modeling ability for extracting multi-grained sequential behaviors over contextual information. In other words, they poorly capture the hierarchical relationship between context relations and item relations that currently influence users’ preferences in a unified framework. Besides, they usually utilize users’ short-term preferences with either static or irrelevant long-term representation for the prediction. To tackle the above issues, in this paper, we propose a novel Context-aware Recommender System Based on a Deep Sequential Learning Approach (CReS) to capture users’ dynamic preferences by modeling the hierarchical relationships between contexts and items in a particular session, and for combining users’ short-term sessions with the relevant long-term representations. Specifically, within a certain session, we design a hierarchical attention network between the identified context relations and items relations, namely CReSession.
 Therefore, with CReSession, we could provide a suitable session representation that mimics the hierarchical user interests on multiple granularities of contextual types and its corresponding items. We then introduce a neural attentive bi-directional GRU network to distill only those highly related to the recent short-term session. Finally, the relevant long-term representations and the short-term session are combined with the sequential residual connection to form the final user representation in a unified manner. With extensive experiments on two real-world datasets, CReS not only achieves significant improvement over the state-of-the-art methods in terms of pre-defined metrics, but also provides an interpretable result regarding why we recommend these items to users.
Recommender systems (RSs) have become key components driving the success of e-commerce and other platforms where revenue and customer satisfaction is dependent on the user’s ability to discover desirable items in large catalogues. As the number of users and items on a platform grows, the computational complexity and the sparsity problem constitute important challenges for any recommendation algorithm. In addition, the most widely studied filtering-based RSs, while effective in providing suggestions for established users and items, are known for their poor performance for the new user and new item (cold-start) problems. Stereotypical modelling of users and items is a promising approach to solving these problems. A stereotype represents an aggregation of the characteristics of the items or users which can be used to create general user or item classes. We propose a set of methodologies for the automatic generation of stereotypes to address the cold-start problem. The novelty of the proposed approach rests on the findings that stereotypes built independently of the user-to-item ratings improve both recommendation metrics and computational performance during cold-start phases. The resulting RS can be used with any machine learning algorithm as a solver, and the improved performance gains due to rate-agnostic stereotypes are orthogonal to the gains obtained using more sophisticated solvers. The paper describes how such item-based stereotypes can be evaluated via a series of statistical tests prior to being used for recommendation. The proposed approach improves recommendation quality under a variety of metrics and significantly reduces the dimension of the recommendation model.
Graph-based recommendation models work well for top-N recommender systems due to their capability to capture the potential relationships between entities. However, most of the existing methods only construct a single global item graph shared by all the users and regrettably ignore the diverse tastes between different user groups. Inspired by the success of local models for recommendation, this paper provides the first attempt to investigate multiple local item graphs along with a global item graph for graph-based recommendation models. We argue that recommendation on global and local graphs outperforms that on a single global graph or multiple local graphs. Specifically, we propose a novel graph-based recommendation model named GLIMG (Global and Local IteM Graphs), which simultaneously captures both the global and local user tastes. By integrating the global and local graphs into an adapted semi-supervised learning model, users' preferences on items are propagated globally and locally. Extensive experimental results on real-world datasets show that our proposed method consistently outperforms the state-of-the art counterparts on the top-N recommendation task.
Session-based recommender systems (SBRSs) aim at predicting the next item via learning the dynamic and short-term preferences of users. Most of the existing SBRSs usually make predictions based on the intra-session dependencies embedded in session information only, ignoring more complex inter-session dependencies and other available side information (e.g., item attributes, users), which in turn greatly limits the improvement of the recommendation accuracy. In order to effectively extract both intra- and inter-session dependencies from not only the session information but also the side information, to further improve the accuracy of next-item recommendations, we propose a novel hypergraph learning (HL) framework. The HL framework mainly contains three modules, i.e., a hypergraph construction module, a hypergraph learning module, and a next-item prediction module. The hypergraph construction module constructs a hypergraph to connect the users, items and item attributes together in a unified way. Then, the hypergraph learning module learns the informative latent representation for each item by extracting both intra- and inter-session dependencies embedded in the constructed hypergraph. Also, a latent representation for each user is learned. After that, the learned latent representations are fed into the next-item prediction module for next-item recommendations. We conduct extensive experiments on two real-world datasets. The experimental results show that our HL framework outperforms the state-of-the-art approaches.
Educational recommender systems channel most of the research efforts on the effectiveness of the recommended items. While teachers have a central role in online platforms, the impact of recommender systems for teachers in terms of the exposure such systems give to the courses is an under-explored area. In this paper, we consider data coming from a real-world platform and analyze the distribution of the recommendations w.r.t. the geographical provenience of the teachers. We observe that data is highly imbalanced towards the United States, in terms of offered courses and of interactions. These imbalances are exacerbated by recommender systems, which overexpose the country w.r.t. its representation in the data, thus generating unfairness for teachers outside that country. To introduce equity, we propose an approach that regulates the share of recommendations given to the items produced in a country (visibility) and the position of the items in the recommended list (exposure).
Existing Collaborative Filtering (CF) methods are mostly designed based on the idea of matching, i.e., by learning user and item embeddings from data using shallow or deep models, they try to capture the associative relevance patterns in data, so that a user embedding can be matched with relevant item embeddings using designed or learned similarity functions. However, as a cognition rather than a perception intelligent task, recommendation requires not only the ability of pattern recognition and matching from data, but also the ability of cognitive reasoning in data. In this paper, we propose to advance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which means that each user knows part of the reasoning space, and they collaborate for reasoning in the space to estimate preferences for each other. Technically, we propose a Neural Collaborative Reasoning (NCR) framework to bridge learning and reasoning. Specifically, we integrate the power of representation learning and logical reasoning, where representations capture similarity patterns in data from perceptual perspectives, and logic facilitates cognitive reasoning for informed decision making. An important challenge, however, is to bridge differentiable neural networks and symbolic reasoning in a shared architecture for optimization and inference. To solve the problem, we propose a modularized reasoning architecture, which learns logical operations such as AND (∧), OR (∨) and NOT (¬) as neural modules for implication reasoning (→). In this way, logical expressions can be equivalently organized as neural networks, so that logical reasoning and prediction can be conducted in a continuous space. Experiments on real-world datasets verified the advantages of our framework compared with both shallow, deep and reasoning models.
The frequency at which new research documents are being published causes challenges for researchers who increasingly need access to relevant documents in order to conduct their research. Searching across a variety of databases and browsing millions of documents to find semantically relevant material is a time-consuming task. Recently, there has been a focus on recommendation algorithms that suggest relevant documents based on the current interests of the researchers. In this paper, we describe the implementation of seven commonly used algorithms and three aggregation algorithms. We evaluate the recommendation algorithms in a large-scale biomedical knowledge base with the goal of identifying relative weaknesses and strengths of each algorithm. We analyze the recommendations from each algorithm based on assessments of output as evaluated by 14 biomedical researchers. The results of our research provide unique insights into the performance of recommendation algorithms against the needs of modern-day biomedical researchers.
Reinforcement Learning (RL) techniques have been sought after as the next-generation tools to further advance the field of recommendation research. Different from classic applications of RL, recommender agents, especially those deployed on commercial recommendation platforms, have to operate in extremely large state and action spaces, serving a dynamic user base in the order of billions, and a long-tail item corpus in the order of millions or billions. The (positive) user feedback available to train such agents is extremely scarce in retrospect. Improving the sample efficiency of RL algorithms is thus of paramount importance when developing RL agents for recommender systems. In this work, we present a general framework to augment the training of model-free RL agents with auxiliary tasks for improved sample efficiency. More specifically, we opt to add additional tasks that predict users' immediate responses (positive or negative) toward recommendations, i.e., user response modeling, to enhance the learning of the state and action representations for the recommender agents. We also introduce a tool based on gradient correlation analysis to guide the model design. We showcase the efficacy of our method in offline experiments, learning and evaluating agent policies over hundreds of millions of user trajectories. We also conduct live experiments on an industrial recommendation platform serving billions of users and tens of millions of items to verify its benefit.
Recommender System (RS) is one of the most popular applications of Artificial Intelligence which attracted researchers all around the world. Many machine learning algorithms are used to develop RSs. Choosing the best machine learning algorithm to provide users with a product or service is the most challenging task in the area of RSs. Now we are witnessing a paradigm shift in the purchase habits of people from in-shop to online resulting in the availability of online information exponentially growing every day. The ever-increasing online information and the number of online users create new avenues in RS. In an online shopping scenario, these systems must be able to recommend relevant items to the users. The RSs have to deal with the huge amount of information by filtering the relevant information based on the analysis made on the inputs made by the users during their online sessions. These systems can recommend appropriate items to users based on their interest and previous preference which can lead to increased sales. The three major techniques used to build a RS are content-based, collaborative based and hybrid-based. This paper presents the various applications of RSs and makes a detailed comparative study of different machine learning approaches used. The methodologies used for identifying research articles for analysis, the merits and demerits of different techniques in RSs and domain-specific applications of these techniques are well explained here with scientific review analysis.
Cross-domain recommendation technique is a promising way to alleviate data sparsity issues by transferring knowledge from an auxiliary domain to a target domain. However, most existing works focus on utilizing the same users among different domains, while ignoring domain-specific users which forms the majority in real-world circumstances. In this paper, we propose a novel cross-domain learning approach--Relation Expansion based Cross-Domain Recommendation (ReCDR) to improve recommendation accuracies on small-overlapped domains. ReCDR first models the interactions in each domain as a local graph. It then forms a shared network by expanding out relationships using pre-trained node similarities. On the enhanced graph, ReCDR adopts a hierarchical attention mechanism. The output embedding will finally be combined with the local feature to balance the result for dual-target task. The proposed model is thoroughly evaluated on three real-world datasets. Experiments demonstrate superior performance compared to state-of-the-art methods.
Abstract Danmaku is an emerging comment design for videos that allows real-time, interactive comments from viewers. Danmaku increases viewers’ interaction with other viewers and streamers, thereby raising viewers’ loyalty and sense of belonging. Sending Danmaku comments demonstrates a higher degree of viewer involvement than traditional static comments below the videos. Therefore, it is necessary and meaningful to learn about viewers’ preferences by observing their behavior, as this may benefit the platform as well as the streamers. However, research on how the multimodal environment affects viewers’ behavior in sending Danmaku comments is quite limited. To fill this gap, we propose a new dataset and a deep neural network integrating multimodal information to predict whether viewers will send Danmaku comments (Deep Multimodal network for Danmaku Forecasting, DMDF) in order to evaluate the impact of the interaction of textual features, audio features and visual features on the behavior of viewers sending Danmaku comments. A series of experimental results based on a real dataset of 249657 samples from Bilibili (a leading Chinese video streaming Website) demonstrate the effectiveness of the proposed DMDF and the helpfulness of all modalities, especially visual and acoustic features, in behavior forecasting. DMDF with the multimodal squeeze-and-excitation (MSE) module we proposed achieves 90.14% on accuracy and 83.60% on F1-score, and it reveals the extent to which a user-generated video can influence viewers to send Danmaku comments, which helps predict viewers’ online viewing behavior. Furthermore, our model contributes to the current work on the video understanding task.
Our research is a step toward ascertaining the need for personalization, in XAI, and we do so in the context of investigating the value of explanations of AI-driven hints and feedback are useful in Intelligent Tutoring Systems (ITS). We added an explanation functionality for the adaptive hints provided by the Adaptive CSP (ACSP) applet, an interactive simulation that helps students learn an algorithm for constraint satisfaction problems by providing AI-driven hints adapted to their predicted level of learning. We present the design of the explanation functionality and the results of a controlled study to evaluate its impact on students' learning and perception of the ACPS hints. The study includes an analysis of how these outcomes are modulated by several user characteristics such as personality traits and cognitive abilities, to asses if explanations should be personalized to these characteristics. Our results indicate that providing explanations increase students' trust in the ACPS hints, perceived usefulness of the hints, and intention to use them again. In addition, we show that students' access of the explanation and learning gains are modulated by user characteristics, providing insights toward designing personalized Explainable AI (XAI) for ITS.
Abstract Social Networking Services (SNSs) provide online platforms for users with two kinds of behavior: user-user social behavior (e.g., following a user, making friends with others) and user-item consumption behavior (e.g., rating, showing likeness, clicking, giving thumbs up to items). With the increasing popularity of SNSs and demand for SNS features, predicting potential social links and recommending preferable items to users have become two hot research lines. However, previous works either modeled just one of these two kinds of behaviors in isolation or only considered the observed user behavior data. In fact, social scientists have long recognized that the user-user and user-item behaviors have a mutual reinforcement effect. On the one hand, the two behaviors have correlations, and they can influence each other. On the other hand, due to the sparsity of the observed user behavior data, the user behavior prediction performance is far from satisfactory, although, using two types of behavioral data at the same time can mitigate the sparsity problem. These two problems remains open: how to better model the correlation of user-user social and user-item consumption activities and how to mitigate the data sparsity issue. In this paper, we propose a random walk based distributed representation learning model to jointly predict these behaviors on SNSs. Specifically, we first construct a joint behavior graph that combines the two behaviors, with the edges denoting the sparse observed user behavior data. Then, we adopt a random walk to capture higher-order relationships between users and items. After that, we utilize a distributed learning approach to embed both users and items into a latent space. In this way, the behavior prediction tasks are transformed into similarity calculations in the latent space. Finally, extensive experimental results using two real-world datasets demonstrate the effectiveness of our proposed approach on the two behavior prediction tasks.
Collaborative bandit learning, i.e., bandit algorithms that utilize collaborative filtering techniques to improve sample efficiency in online interactive recommendation, has attracted much research attention as it enjoys the best of both worlds. However, all existing collaborative bandit learning solutions impose a stationary assumption about the environment, i.e., both user preferences and the dependency among users are assumed static over time. Unfortunately, this assumption hardly holds in practice due to users' ever-changing interests and dependency relations, which inevitably costs a recommender system sub-optimal performance in practice. In this work, we develop a collaborative dynamic bandit solution to handle a changing environment for recommendation. We explicitly model the underlying changes in both user preferences and their dependency relation as a stochastic process. Individual user's preference is modeled by a mixture of globally shared contextual bandit models with a Dirichlet process prior. Collaboration among users is thus achieved via Bayesian inference over the global bandit models. To balance exploitation and exploration during the interactions, Thompson sampling is used for both model selection and arm selection. Our solution is proved to maintain a standard ~O(√T) Bayesian regret in this challenging environment. Extensive empirical evaluations on both synthetic and real-world datasets further confirmed the necessity of modeling a changing environment and our algorithm's practical advantages against several state-of-the-art online learning solutions.
Matrix factorization algorithm is one of the recommendable algorithms. In order to tackle the inefficiencies of the traditional matrix factorization algorithm like the slow training time and the insufficient computing resource for the mass data, a parallelization algorithm of singular value decomposition (SVD) under the Spark framework is proposed to perform SVD, standardization, and dimensionality reduction for the user-rating matrix, and obtain the user-feature matrix and project-feature matrix. The recommendation model is obtained by determining the prediction rating. MovieLens data show that this algorithm can significantly shorten the training time of the model, improve the running efficiency of the recommendation algorithms for the mass data, and improve the algorithm accuracy.
One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model, and then use some approximate nearest neighbor (ANN) search algorithm to find top candidates. In this paper, we present Deep Retrieval (DR), to learn a retrievable structure directly with user-item interaction data (e.g. clicks) without resorting to the Euclidean space assumption in ANN algorithms. DR's structure encodes all candidate items into a discrete latent space. Those latent codes for the candidates are model parameters and learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the structure is performed to retrieve the top candidates for reranking. Empirically, we first demonstrate that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline on two public datasets. Moreover, we show that, in a live production recommendation system, a deployed DR approach significantly outperforms a well-tuned ANN baseline in terms of engagement metrics. To the best of our knowledge, DR is among the first non-ANN algorithms successfully deployed at the scale of hundreds of millions of items for industrial recommendation systems.
Logic diagnosis is a software-based methodology to identify the behavior and location of defects in failing integrated circuits, which is an essential step in yield learning. Conventionally, accurate diagnosis requires a sufficient amount of failing data, indicating a high test cost. Prior work that attempt to solve this problem either use a fixed pattern order, ignoring the characteristics of each chip, or require significant memory which leads to unacceptable increases in test cost. In this work, a new algorithm is described for dynamically selecting the test pattern order that leads to significant reduction in memory cost. Experiments using two industrial chips demonstrate the efficacy of the approach. Compared to prior work, the algorithm described in this work uses as little as 1/500 of tester space to store failing data.
Recommender systems have already been introduced in several industries such as retailing and entertainment, with great success. However, their application in the airline industry remains in its infancy. We discuss why this has been the case and why this situation is about to change in light of IATA’s New Distribution Capability standard. We argue that recommender systems, as a component of the Offer Management System, hold the key to providing customer centricity with their ability to understand and respond to the needs of the customers through all touchpoints during the traveler journey. We present six recommender system use cases that cover the entire traveler journey and we discuss the particular mind-set and needs of the customer for each of these use cases. Recent advancements in Artificial Intelligence have enabled the development of a new generation of recommender systems to provide more accurate, contextualized and personalized offers to customers. This paper contains a systematic review of the different families of recommender system algorithms and discusses how the use cases can be implemented in practice by matching them with a recommender system algorithm.
Collaborative filtering (CF) methods are making an impact on our daily lives in a wide range of applications, including recommender systems and personalization. Latent factor methods, e.g., matrix factorization (MF), have been the state-of-the-art in CF, however they lack interpretability and do not provide a straightforward explanation for their predictions. Explainability is gaining momentum in recommender systems for accountability, and because a good explanation can swing an undecided user. Most recent explainable recommendation methods require auxiliary data such as review text or item content on top of item ratings. In this paper, we address the case where no additional data are available and propose augmenting the classical MF framework for CF with a prior that encodes each user's embedding as a sparse linear combination of item embeddings, and vice versa for each item embedding. Our XPL-CF approach automatically reveals these user-item relationships, which underpin the latent factors and explain how the resulting recommendations are formed. We showcase the effectiveness of XPL-CF on real data from various application domains. We also evaluate the explainability of the user-item relationship obtained from XPL-CF through numeric evaluation and case study examples.
The study of niche suitability of modern tram design can promote the virtuous circle of urban ecology, coordinate the contradiction between modern tram and ecological problems, and provide a theoretical for the solution of design problems. The evaluation results can be used for the optimization and improvement of design schemes. The index system of niche suitability of modern tram design was established, aiming at the design problems of modern tram in the development process based on the perspective of ecological evaluation. The Cloud-TOPSIS method was put forward to evaluate and analyze the index system, and the evaluation model of niche suitability of modern tram design is obtained.
Recently, recommender systems based on Graph Convolution Network (GCN) have become a research hotspot, especially in collaborative filtering. However, most GCN-based models have inferior embedding propagation mechanism, leading to low information extraction efficiency. Besides, the existing methods suffer from high computational complexity for large user-item interaction graphs. In order to solve the above problems, we propose LII-GCCF that integrates Linear transformation, Initial residual and Identity mapping into the Graph Convolutional Collaborative Filtering model. First, initial residual and identity mapping are applied to optimize the information propagation of graph convolution, which privide abundant interaction and alleviate information loss problem. Second, LII-GCCF removes the unnecessary nonlinear transformation based on the characteristics of collaborative filtering to simplify the graph convolution process. Comprehensive experiments are conducted on two public datasets, and the results demonstrate that LII-GCCF has a significant improvement over other state-of-the-art methods.
The information education mode supported by emerging technologies such as big data technology, cloud computing, communication and the Internet of Things is called intelligent education. The purpose of promoting intelligent education is to make use of developed countries and emerging technological means to create intelligent, effective and accurate education methods and adopt correct talent training methods based on the results of big data calculation, thus laying a good foundation for the cultivation of high quality technology and technical talents. Intelligent education platform is a new way of education communication which is constantly improved and developed along with the Internet and education digitization and information. On the one hand, it brings students great convenience, but also provides a new way of learning; On the other hand, it also proposes a solution to the phenomenon of "information overload" caused by the rapid increment of learning resources. Secondly, students who have no basic knowledge of courses will have more choices in choosing courses and learning paths.
Product reviews can provide rich information about the opinions users have of products. However, it is nontrivial to effectively infer user preference and item characteristics from reviews due to the complicated semantic understanding. Existing methods usually learn features for users and items from reviews in single static fashions and cannot fully capture user preference and item features. In this article, we propose a neural review-based recommendation approach that aims to learn comprehensive representations of users/items under a three-tier attention framework. We design a review encoder to learn review features from words via a word-level attention, an aspect encoder to learn aspect features via a review-level attention, and a user/item encoder to learn the final representations of users/items via an aspect-level attention. In word- and review-level attentions, we adopt the context-aware mechanism to indicate importance of words and reviews dynamically instead of static attention weights. In addition, the attentions in the word and review levels are of multiple paradigms to learn multiple features effectively, which could indicate the diversity of user/item features. Furthermore, we propose a personalized aspect-level attention module in user/item encoder to learn the final comprehensive features. Extensive experiments are conducted and the results in rating prediction validate the effectiveness of our method.
Recommender systems exploit interaction history to estimate user preference, having been heavily used in a wide range of industry applications. However, static recommendation models are difficult to answer two important questions well due to inherent shortcomings: (a) What exactly does a user like? (b) Why does a user like an item? The shortcomings are due to the way that static models learn user preference, i.e., without explicit instructions and active feedback from users. The recent rise of conversational recommender systems (CRSs) changes this situation fundamentally. In a CRS, users and the system can dynamically communicate through natural language interactions, which provide unprecedented opportunities to explicitly obtain the exact preference of users. Considerable efforts, spread across disparate settings and applications, have been put into developing CRSs. Existing models, technologies, and evaluation methods for CRSs are far from mature. In this paper, we provide a systematic review of the techniques used in current CRSs. We summarize the key challenges of developing CRSs into five directions: (1) Question-based user preference elicitation. (2) Multi-turn conversational recommendation strategies. (3) Dialogue understanding and generation. (4) Exploitation-exploration trade-offs. (5) Evaluation and user simulation. These research directions involve multiple research fields like information retrieval (IR), natural language processing (NLP), and human-computer interaction (HCI). Based on these research directions, we discuss some future challenges and opportunities. We provide a road map for researchers from multiple communities to get started in this area. We hope this survey helps to identify and address challenges in CRSs and inspire future research.
We consider an online model for recommendation systems, with each user being recommended an item at each time-step and providing ‘like’ or ‘dislike’ feedback. Each user may be recommended a given item at most once. A latent variable model specifies the user preferences: both users and items are clustered into types. All users of a given type have identical preferences for the items, and similarly, items of a given type are either all liked or all disliked by a given user. We assume that the matrix encoding the preferences of each user type for each item type is randomly generated; in this way, the model captures structure in both the item and user spaces, the amount of structure depending on the number of each of the types. The measure of performance of the recommendation system is the expected number of disliked recommendations per user, defined as expected regret. We propose two algorithms inspired by user-user and item-item collaborative filtering (CF), modified to explicitly make exploratory recommendations, and prove performance guarantees in terms of their expected regret. For two regimes of model parameters, with structure only in item space or only in user space, we prove information-theoretic lower bounds on regret that match our upper bounds up to logarithmic factors. Our analysis elucidates system operating regimes in which existing CF algorithms are nearly optimal.
Abstract Today, recommender systems play a vital role in the acceleration of searches by internet users to find what they are interested in. Among the strategies proposed for recommender systems, collaborative filtering has received due attention regarding its simplicity and efficiency. The key factor for the success of this strategy returns to the similarity calculation methods that affect the accuracy of its recommendations. Regarding the large volume of articles published in the field of collaborative filtering for the development of recommender systems, it is necessary to provide a comprehensive review of the similarity functions and their efficiency presented in the field. Of course, several surveys have already been published to investigate the similarity functions proposed for collaborative filtering, but these articles either have looked briefly at these functions or reviewed a few numbers of them. In this study, the effort was to provide a comprehensive study on the similarity functions proposed for collaborative filtering with a special focus on the rating-based and neighbor-based approaches. After a brief explanation of each similarity function, some popular evaluation metrics were used for their evaluation using the MovieLens datasets. The comparative evaluation results presented in this article provide a highly useful reference for researchers in this field to choose their appropriate similarity function.
Recently, research on explainable recommender systems has drawn much attention from both academia and industry, resulting in a variety of explainable models. As a consequence, their evaluation approaches vary from model to model, which makes it quite difficult to compare the explainability of different models. To achieve a standard way of evaluating recommendation explanations, we provide three benchmark datasets for EXplanaTion RAnking (denoted as EXTRA), on which explainability can be measured by ranking-oriented metrics. Constructing such datasets, however, poses great challenges. First, user-item-explanation triplet interactions are rare in existing recommender systems, so how to find alternatives becomes a challenge. Our solution is to identify nearly identical sentences from user reviews. This idea then leads to the second challenge, i.e., how to efficiently categorize the sentences in a dataset into different groups, since it has quadratic runtime complexity to estimate the similarity between any two sentences. To mitigate this issue, we provide a more efficient method based on Locality Sensitive Hashing (LSH) that can detect near-duplicates in sub-linear time for a given query. Moreover, we make our code publicly available to allow researchers in the community to create their own datasets.
Recent studies have shown that there exhibits significantly imbalanced medical resource allocation across public hospitals. Patients, regardless of their diseases, tend to choose hospitals and physicians with a better reputation, which often overloads major hospitals while leaving others underutilized. Guiding patients to hospitals that can serve their treatment needs both timely and with good quality can make the best use of precious medical resources. Unfortunately, it remains one of the major challenges both for research and in practice. In this article, we propose a novel diversity-enhanced hierarchical physician recommendation approach to address this issue. We adopt matrix factorization to estimate physician competency and exploit implicit similarity relationships to improve the competency estimation of physicians that we are of little information of. We then balance the patient preference and physician diversity using two novel heuristic algorithms. We evaluate our proposed approach and compare it with the state of the art. Experiments show that our approach significantly improves both accuracy and recommendation diversity over existing approaches.
This paper summarizes and reviews the latest research progress on the evaluation metrics of the recommendation system, expounds from multiple perspectives such as accuracy, diversity, novelty, and conducts an in-depth analysis of their respective advantages and disadvantages and applicable environments, focuses on the three levels of recommended diversity and evaluation criteria, and makes predictions on the development direction of the evaluation metrics of the recommendation system.
Efficient inner product search on embedding vectors is often the vital stage for online ranking services, such as recommendation and information retrieval. Recommendation algorithms, e.g., matrix factorization, typically produce latent vectors to represent users or items. The recommendation services are conducted by retrieving the most relevant item vectors given the user vector, where the relevance is often defined by inner product. Therefore, developing efficient recommender systems often requires solving the so-called maximum inner product search (MIPS) problem. In the past decade, there have been many studies on efficient MIPS algorithms. This task is challenging in part because the inner product does not follow the triangle inequality of metric space. Compared with hash-based or quantization-based MIPS solutions, in recent years graph-based MIPS algorithms have demonstrated their strong empirical advantages in many real-world MIPS tasks. In this paper, we propose a new index graph construction method named norm adjusted proximity graph (NAPG), for efficient MIPS. With adjusting factors estimated on sampled data, NAPG is able to select more meaningful data points to connect with when constructing graph-based index for inner product search. Our extensive experiments on a variety of datasets verify that the improved graph-based index strategy provides another strong addition to the pool of efficient MIPS algorithms.
Location-based services encompass a spectrum of services. Today, it is easier to locate or search for our favorite restaurant, shop, etc., under these services. It helps us get access to important and up-to-date information about their surroundings on a single tap. This research proposes two location-based recommendation systems by using the collaborative and content-based filtering recommendation techniques. The first one is a personalized location-based recommender that uses the content filtering technique. In this recommender, the behavioral patterns are extracted from the user’s location history and then provide personalized recommendations based on patterns. Apriori algorithm has been used to extract user-specific behavioral patterns based on time zone, weekday, and location type. The second one is a generalized location-based recommender that uses the collaborative filtering technique. It employs the K-means clustering algorithm and the silhouette metric and elbow method to find the optimal index K (clusters).
Recommender systems are information filtering systems used in many online applications like music and video broadcasting and e-commerce platforms. They are also increasingly being applied to facilitate software engineering activities. Following this trend, we are witnessing a growing research interest on recommendation approaches that assist with modelling tasks and model-based development processes. In this paper, we report on a systematic mapping review (based on the analysis of 66 papers) that classifies the existing research work on recommender systems for model-driven engineering (MDE). This study aims to serve as a guide for tool builders and researchers in understanding the MDE tasks that might be subject to recommendations, the applicable recommendation techniques and evaluation methods, and the open challenges and opportunities in this field of research.

)is paper considers current personalized recommendation approaches based on computational social systems and then discusses their advantages and application environments. )e most widely used recommendation algorithm, personalized advice based on collaborative filtering, is selected as the primary research focus. Some improvements in its application performance are analyzed. First, for the calculation of user similarity, the introduction of computational social system attributes can help to determine users’ neighbors more accurately. Second, computational social system strategies can be adopted to penalize popular items. )ird, the network community, identity, and trust can be combined as there is a close relationship. )erefore, this paper proposes a new method that uses a computational social system, including a trust model based on community relationships, to improve the user similarity calculation accuracy to enhance personalized recommendation. Finally, the improved algorithm in this paper is tested on the online reading website dataset. )e experimental results show that the enhanced collaborative filtering algorithm performs better than the traditional algorithm.
Session-based recommendation is a task to recommend the next clicked item when the user’s current interaction sequence is given. Accurately modeling the session representation is critical for session-based recommendation. However, we find that most current methods for session-based recommendation just use conscious behavior and information in the current session, ignoring the information of unconscious behavior in the current session and preference interaction with neighborhood sessions. In this paper, we propose a Mixed Behaviors and Preference Interaction model (MBPI), which utilizes conscious and unconscious behaviors and parallel co-attention mechanism, for session-based recommendation. In MBPI, we apply a Gated Recurrent Unit (GRU) to generate the session global preference, and employ another GRU with an item-level attention mechanism to explore the session local preference, with the multi-feature behaviors. Then, we introduce a parallel co-attention mechanism to capture the preference interaction with the help of the current session and neighborhood sessions and to update the two preferences of the current session. Finally, we combine the session global preference and session local preference as session representation and make recommendation. Experimental results on three real-world datasets show our method outperforms the state-of-the-art methods and validate the effectiveness of our approach.
K-nearest neighbors (KNN) has been successfully used for recommendation, but querying neighbors of high quality is nearly impossible when the feature space is small or has limited training data. However, due to privacy requirements and government policies, directly transferring data from one data owner to another is not workable. Therefore, we propose a novel KNN approach, secured federated KNN (SF-KNN), that takes privacy requirements into consideration and builds a federated model to gain global neighbors with joint parties, in order to improve the model performance. Specifically, it empowers the parties to train high-quality models with little data. More importantly, it makes cross-domain training possible. We implement SF-KNN on Euclidean and cosine metrics using user-based and item-based methods. In our experiment, we evaluate the proposed SF-KNN on three data sources, MovieLens, Netflix, and Amazon, and several diverse domains, movies, books, clothes, jewellery and food, by comparing it against various baselines. The experiment results indicate that SF-KNN is able to learn more precise neighbors than a local KNN trained by parties individually. In general, it outperforms the local KNN on all of the datasets, reaching 15% average accuracy gain on the Euclidean metric and 8% of it on the cosine metric when simulating 10 parties across all data sources.
Knowledge graphs (KGs) have proven to be effective for high-quality recommendation. Most efforts, however, explore KGs by either extracting separate paths connecting user-item pairs, or iteratively propagating user preference over the entire KGs, thus failing to efficiently exploit KGs for enhanced recommendation. In this paper, we design a novel attentive knowledge graph embedding (AKGE) framework for recommendation, which sufficiently exploits both semantics and topology of KGs in an interaction-specific manner. Specifically, AKGE first automatically extracts high-order subgraphs that link user-item pairs with rich semantics, and then encodes the subgraphs by the proposed attentive graph neural network to learn accurate user preference. Extensive experiments on three real-world datasets demonstrate that AKGE consistently outperforms state-of-the-art methods. It additionally provides potential explanations for the recommendation results.
Prior work on personalized recommendations has focused on exploiting explicit signals from user-specific queries, clicks, likes, and ratings. This paper investigates tapping into a different source of implicit signals of interests and tastes: online chats between users. The paper develops an expressive model and effective methods for personalizing search-based entity recommendations. User models derived from chats augment different methods for re-ranking entity answers for medium-grained queries. The paper presents specific techniques to enhance the user models by capturing domain-specific vocabularies and by entitybased expansion. Experiments are based on a collection of online chats from a controlled user study covering three domains: books, travel, food. We evaluate different configurations and compare chat-based user models against concise user profiles from questionnaires. Overall, these two variants perform on par in terms of NCDG@20, but each has advantages in certain domains.
Purchase intent forecasting, which aims to model user consumption behavior over different categories of items, plays a key role in many services, like online retailing systems, computational advertising and personalized recommendations. While the recently emerged deep neural network models (e.g., recurrent neural network, or attention mechanism) have been proposed to understand user’s sequential behavior, we argue that the successes of these methods is largely rely on the data sufficiency. However, the practical purchase forecasting scenarios involve highly sparse data distributions across categories and time. In such cases, one has to deal with the data imbalance problem in order to encode the complex patterns of user purchase behaviors. To tackle this challenge, we develop a Convolutional Hierarchical TRansformer networks (CHTR), to enable the purchase pattern modeling with the multi-grained temporal dynamics, so as to alleviate the data imbalance issue. In our CHTR framework, we develop a multi-grained hierarchical transformer network, to make the learned behavior embeddings be reflective of the multi-level relational structures. Then, a dependency modeling component is proposed to aggregate the multi-relational context signals and capture the underlying dependent structures. Our experiments on real-world datasets show the significant improvements obtained by CHTR over different types of alternative methods.
Clustering-based approaches have been demonstrated to be efficient and scalable to large-scale data sets. However, clustering-based recommender systems suffer from relatively low accuracy and coverage. To address these issues, we propose in this article an optimized multiview clustering approach for the recommendation of items in social networks. First, the selection of the initial medoids is optimized using the Bees Swarm optimization algorithm (BSO) in order to generate better partitions (i.e. refining the quality of medoids according to the objective function). Then, the multiview clustering (MV) is applied, where users are iteratively clustered from the views of both rating patterns and social information (i.e. friendships and trust). Finally, a framework is proposed for testing the different alternatives, namely: (1) the standard recommendation algorithms; (2) the clustering-based and the optimized clustering-based recommendation algorithms using BSO; and (3) the MV and the optimized MV (BSO-MV) algorithms. Experimental results conducted on two real-world datasets demonstrate the effectiveness of the proposed BSO-MV algorithm in terms of improving accuracy, as it outperforms the existing related approaches and baselines.
The large-scale recommender system mainly consists of two stages: matching and ranking. The matching stage (also known as the retrieval step) identifies a small fraction of relevant items from billion-scale item corpus in low latency and computational cost. Item-to-item collaborative filtering (item-based CF) and embedding-based retrieval (EBR) have been long used in the industrial matching stage owing to its efficiency. However, item-based CF is hard to meet personalization, while EBR has difficulty in satisfying diversity. In this paper, we propose a novel matching architecture, Path-based Deep Network (named PDN), through incorporating both personalization and diversity to enhance matching performance. Specifically, PDN is comprised of two modules: Trigger Net and Similarity Net. PDN utilizes Trigger Net to capture the user's interest in each of his/her interacted item. Similarity Net is devised to evaluate the similarity between each interacted item and the target item based on these items' profile and CF information. The final relevance between the user and the target item is calculated by explicitly considering user's diverse interests, \ie aggregating the relevance weights of the related two-hop paths (one hop of a path corresponds to user-item interaction and the other to item-item relevance). Furthermore, we describe the architecture design of the proposed PDN in a leading real-world E-Commerce service (Mobile Taobao App). Based on offline evaluations and online A/B test, we show that PDN outperforms the existing solutions for the same task. The online results also demonstrate that PDN can retrieve more personalized and more diverse items to significantly improve user engagement. Currently, PDN system has been successfully deployed at Mobile Taobao App and handling major online traffic.
Recommender systems provide recommendations to users using background data such as ratings of users about items and features of items. These systems are used in several areas such as e-commerce, news websites, and article websites. By using recommender systems, customers are provided with relevant data as soon as possible and are able to make good decisions. There are more studies about recommender systems and improving their performance. In this study, prediction performances of neural networks are evaluated and their performances are improved using genetic algorithms. Performances obtained in this study are compared with those of other studies. After that, superiority of this study is shown. While multilayer perceptron, generalized feed-forward network, and coactive neuro fuzzy inference systems were used as neural network algorithms, Movielens 100K and Movielens 1M datasets, which are widely preferred in recommender system studies, were used to train and test the system in the present study. Mean square error and root mean square error were employed as performance metrics. As a result, it was observed that genetic algorithm improves performance of neural networks, and prediction performance of hybrid combination of neural networks and genetic algorithm is superior to prediction performance of recommender systems available in the literature.
At the present time, sequential item recommendation models are compared by calculating metrics on a small item subset (target set) to speed up computation. The target set contains the relevant item and a set of negative items that are sampled from the full item set. Two well-known strategies to sample negative items are uniform random sampling and sampling by popularity to better approximate the item frequency distribution in the dataset. Most recently published papers on sequential item recommendation rely on sampling by popularity to compare the evaluated models. However, recent work has already shown that an evaluation with uniform random sampling may not be consistent with the full ranking, that is, the model ranking obtained by evaluating a metric using the full item set as target set, which raises the question whether the ranking obtained by sampling by popularity is equal to the full ranking. In this work, we re-evaluate current state-of-the-art sequential recommender models from the point of view, whether these sampling strategies have an impact on the final ranking of the models. We therefore train four recently proposed sequential recommendation models on five widely known datasets. For each dataset and model, we employ three evaluation strategies. First, we compute the full model ranking. Then we evaluate all models on a target set sampled by the two different sampling strategies, uniform random sampling and sampling by popularity with the commonly used target set size of 100, compute the model ranking for each strategy and compare them with each other. Additionally, we vary the size of the sampled target set. Overall, we find that both sampling strategies can produce inconsistent rankings compared with the full ranking of the models. Furthermore, both sampling by popularity and uniform random sampling do not consistently produce the same ranking when compared over different sample sizes. Our results suggest that like uniform random sampling, rankings obtained by sampling by popularity do not equal the full ranking of recommender models and therefore both should be avoided in favor of the full ranking when establishing state-of-the-art.
Abstract Reviewing is the most important step in the quality accreditation of scientific works, requires the professional expertise of the reviewer as well as there is no conflict of interest in the evaluation process. However, we also acknowledge that reviewers have limited knowledge, experience and opinions about the work of others, so they may misinterpret the author’s point of view, leading to the rejection of excellent scientific work or a potentially successful project proposal. Manually selecting reviewers can lead to bias and time-consuming. To solve these problems, we have developed a support system for selecting a group of reviewers to evaluate a particular problem, such as a proposal or a research paper. Our support system consists of three main modules: data collection, reviewer identification and group prediction of reviewers. The Data Collection module collects data from a variety of sources to create the scientist profile database. The reviewer identification module recognizes reviewers on a specific topic. The reviewer prediction module provides a group of exp reviewers to evaluate a submitted paper or a proposal. Experiments on the DBLP computer science bibliography dataset showed that our system achieves better results in terms of accuracy in comparison to other methods.
Newsletters have (re-) emerged as a powerful tool for publishers to engage with their readers directly and more effectively. Despite the diversity in their audiences, publishers’ newsletters remain largely a one-size-fits-all offering, which is suboptimal. In this paper, we present NU:BRIEF, a web application for publishers that enables them to personalize their newsletters without harvesting personal data. Personalized newsletters build a habit and become a great conversion tool for publishers, providing an alternative readers-generated revenue model to a declining ad/clickbait-centered business model. Demo: https://demo.nubrief.com/md03PaAJSwXMegL5BbKpQlArK3elb3hDUglcHodx4gE=/ Explainer video: https://www.youtube.com/watch?v=AUZGuyPJYH4
In this article, we survey machine learning and predictive analytics methods for medical informatics. We begin by surveying the current state of practice, key task definitions, and open research problems related to predictive modeling in diagnostic medicine. This follows the traditional supervised, unsupervised, and reinforcement learning taxonomy. Next, we review current research on semi-supervised, active, and transfer learning, and on differentiable computing methods such as deep learning. The focus of this section is on deep neural networks with common use cases in computational medicine, including self-supervised learning scenarios: these include convolutional neural networks for image analysis, recurrent neural networks for time series, and generative adversarial models for correction of class imbalance in differential diagnosis and anomaly detection. We then continue by assessing salient connections between the current state of machine learning research and data-centric healthcare analytics, focusing specifically on diagnostic imaging and multisensor integration as crucial research topics within predictive analytics. This section includes synthesis experiments on analytics and multisensor data fusion within a diagnostic test bed. Finally, we conclude by relating open problems of machine learning for prediction-based medical informatics surveyed in this article to the impact of big data and its associated challenges, trends, and limitations of current work, including privacy and security of sensitive patient data.
Recommender systems generate personalized recommendations for users based on their historical data. However, if some users have few interactions in the training data, i.e., few-shot users, recommendations for them will be inaccurate. In this paper, we propose a setwise attentional neural similarity method (SANS) for the few-shot recommendation problem. Unlike general recommendation algorithms, we eliminate direct representations of few-shot users. First, a neural similarity method is proposed to effectively estimate the correlation between items. Then, we propose a setwise attention mechanism to obtain recommendation scores by aggregating the correlations between a candidate item and items in a candidate user’s historical interactions. To facilitate model training in the few-shot scenario, training samples are generated by episode sampling, and each training sample is assigned with an adaptive weight to emphasize the importance of few-shot users. We simulate the few-shot recommendation problem on three real-world datasets and extensive results show that SANS can outperform the state-of-the-art recommendation algorithms in few-shot recommendation.
This work presents a generalized local factor model, namely Local Collaborative Autoencoders (LOCA). To our knowledge, it is the first generalized framework under the local low-rank assumption that builds on the neural recommendation models. We explore a large number of local models by adopting a generalized framework with different weight schemes for training and aggregating them. Besides, we develop a novel method of discovering a sub-community to maximize the coverage of local models. Our experimental results demonstrate that LOCA is highly scalable, achieving state-of-the-art results by outperforming existing AE-based and local latent factor models on several large-scale public benchmarks.
Os sistemas de recomendação possuem o objetivo de sugerir aos seus usuário itens, produtos ou informações de acordo com seus interesses, fazendo com que sua utilização seja cada vez mais difundida, tanto no mercado como em processos de tomada de decisão. Com base no contexto descrito, esse trabalho busca disponibilizar um serviço de recomendação híbrido implantado sobre a estrutura de um WebService RESTful, focado na estruturação dos resultados obtidos em algoritmos de recomendação baseados em filtragem colaborativa, conteúdo e hébrida (utilizando as abordagens ponderada e mista). Foi elaborado um estudo de caso baseado em avaliações de musicas dos mais variados gêneros. O algoritmo de filtragem híbrida ponderada obteve os melhores resultados com 81,4% de acerto nas recomendações, bem como, media das recomendações estatisticamente iguais as medias de avaliações, com base no teste de T.
Abstract Quality of Service (QoS) prediction and privacy preservation are two key challenges in service recommendation. Nevertheless, the existing QoS prediction methods cannot be directly utilized in edge computing networks (ECNs) due to the user mobility and distribution nature in these networks. To address this problem, the DEQP2 model, a distributed edge QoS prediction model with privacy-preserving, is proposed in this paper. In the DEQP2 model, the Laplace vector mechanism is first employed for distributed privacy protection processing at the edge. Then, the distributed edge differential privacy (DEDP) QoS prediction algorithm is proposed, to enable a comprehensive consideration of the influence of user preferences and the edge environment. Finally, we conduct experiments on the EdgeQoS dataset, which is an integrated dataset derived from the WSDream and Telecom real-world datasets. The experimental results show that the proposed DEQP2 model provides measurable privacy preservation without significantly reducing the accuracy.
CTR prediction, which aims to estimate the probability that a user will click an item, plays a crucial role in online advertising and recommender system. Feature interaction modeling based and user interest mining based methods are the two kinds of most popular techniques that have been extensively explored for many years and have made great progress for CTR prediction. However, (1) feature interaction based methods which rely heavily on the co-occurrence of different features, may suffer from the feature sparsity problem (i.e., many features appear few times); (2) user interest mining based methods which need rich user behaviors to obtain user's diverse interests, are easy to encounter the behavior sparsity problem (i.e., many users have very short behavior sequences). To solve these problems, we propose a novel module named Dual Graph enhanced Embedding, which is compatible with various CTR prediction models to alleviate these two problems. We further propose a Dual Graph enhanced Embedding Neural Network(DG-ENN) for CTR prediction. Dual Graph enhanced Embedding exploits the strengths of graph representation with two carefully designed learning strategies (divide-and-conquer, curriculum-learning-inspired organized learning) to refine the embedding. We conduct comprehensive experiments on three real-world industrial datasets. The experimental results show that our proposed DG-ENN significantly outperforms state-of-the-art CTR prediction models. Moreover, when applying to state-of-the-art CTR prediction models, Dual graph enhanced embedding always obtains better performance. Further case studies prove that our proposed dual graph enhanced embedding could alleviate the feature sparsity and behavior sparsity problems. Our framework will be open-source based on MindSpore in the near future.
Abstract Travel recommendation is very critical to helping users quickly find products or services that they are interested in. The key to travel recommender systems is learning user shopping intentions, which are expressed through various supervision signals, such as the clicked products and their titles. Existing travel recommendation methods commonly infer user intentions from click behaviors on travel products. However, remarkable keywords in the product title, such as departure, destination, travel time, hotel, and transportation are paid less attention. To this end, we hypothesize that modeling click sequences and product keywords in title jointly would result in a more holistic representation of a product and towards more accurate recommendations. Thus, we propose a TRKG (short for Travel Recommendation with Keywords Generation) model, which fulfills the travel recommendation and keywords generation tasks simultaneously. To generate explainable outputs, unlike most previous approaches that regard the product title as a hidden feature vector, TRKG regards keywords in the product title as an additional supervision signal. Meanwhile, TRKG integrates the long-term and short-term user preferences in the travel recommendation component and the keywords generation component. To evaluate the proposed model, we constructed datasets from a large tourism e-commerce website in China. Extensive experiments demonstrate that the proposed method yields significant improvements over state-of-the-art methods.
Next basket recommendation aims to infer a set of items that a user will purchase at the next visit by considering a sequence of baskets he/she has purchased previously. This task has drawn increasing attention from both the academic and industrial communities. The existing solutions mainly focus on sequential modeling over their historical interactions. However, due to the diversity and randomness of users' behaviors, not all these baskets are relevant to help identify the user's next move. It is necessary to denoise the baskets and extract credibly relevant items to enhance recommendation performance. Unfortunately, this dimension is usually overlooked in the current literature. To this end, in this paper, we propose a Contrastive Learning Model~(named CLEA) to automatically extract items relevant to the target item for next basket recommendation. Specifically, empowered by Gumbel Softmax, we devise a denoising generator to adaptively identify whether each item in a historical basket is relevant to the target item or not. With this process, we can obtain a positive sub-basket and a negative sub-basket for each basket over each user. Then, we derive the representation of each sub-basket based on its constituent items through a GRU-based context encoder, which expresses either relevant preference or irrelevant noises regarding the target item. After that, a novel two-stage anchor-guided contrastive learning process is then designed to simultaneously guide this relevance learning without requiring any item-level relevance supervision. To the best of our knowledge, this is the first work of performing item-level denoising for a basket in an end-to-end fashion for next basket recommendation. Extensive experiments are conducted over four real-world datasets with diverse characteristics. The results demonstrate that our proposed CLEA achieves significantly better recommendation performance than the existing state-of-the-art alternatives. Moreover, further analysis also shows that CLEA can successfully discover the real relevant items towards the recommendation decision.
Abstract The impact of price and price changes should not be ignored while designing algorithms for predicting customer choice. Consumer preferences should be modeled with consideration of price effects. Businesses need to consider for efficient prediction of an individual's purchase behaviour. Personalized recommendation systems have been studied with machine learning algorithms. However, the price-aware personalized recommendation has received little attention. In this paper, we attempt to capture insightful economic results considered in the marketing and economics disciplines by employing modern machine learning architecture for predicting customer choice in a large-scale supermarket context. We extract personalized price sensitivities and examine their importance in consumer behaviour. The employed data collected from a supermarket chain in Germany consists of implicit feedback based on customer-product interactions and the price of every interaction. We propose a two-pathway matrix factorization (2way-MF) model that is price-aware and tries to memorize customer-product interaction's implicit feedback. The proposed models achieve better model performance than standard Matrix Factorization models widely used in the industry. The approach was re-validated with data from supermarket chain in Taiwan. Other industries can adopt the proposed framework of modeling customer's preferences based on price sensitivity. We suggest that further research and analyses could help understand the cross-price elasticities.
Side information of items, e.g., images and text description, has shown to be effective in contributing to accurate recommendations. Inspired by the recent success of pre-training models on natural language and images, we propose a pre-training strategy to learn item representations by considering both item side information and their relationships. We relate items by common user activities, e.g., co-purchase, and construct a homogeneous item graph. This graph provides a unified view of item relations and their associated side information in multimodality. We develop a novel sampling algorithm named MCNSampling to select contextual neighbors for each item. The proposed Pre-trained Multimodal Graph Transformer (PMGT) learns item representations with two objectives: 1) graph structure reconstruction, and 2) masked node feature reconstruction. Experimental results on real datasets demonstrate that the proposed PMGT model effectively exploits the multimodality side information to achieve better accuracies in downstream tasks including item recommendation and click-through ratio prediction. In addition, we also report a case study of testing PMGT in an online setting with 600 thousand users.
Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.
In the recommendation systems (RSs), it is imperative to incorporate the hidden contextual meaning of users’ provided ratings in the similarity computation. To draw such contextual meanings, existing models use the fixed categorization of accessible ratings. However, due to the excessive variation in similarly co-rated item pairs, they produce ambiguous contextual meanings that yield inconsistent results for the user pairs similarities. Therefore, to deal with this problem, this paper proposes an adaptive divisional categorization (ADC)-based RS, namely ADC@𝜃r, that obtains the optimal contextual divisions of accessible ratings under the rating threshold 𝜃r. Here, accessible ratings are the numerical scores that RS users use to express their preferences on the underlying items. A set of adaptive divisions under rating threshold 𝜃r is termed optimal if most of its rating divisions cover a large portion of rating records of a given dataset. For so, the proposed ADC@𝜃r model keeps only those divisions of ratings whose significance values are high, i.e., cover a large portion of the rating records by the ratings of these divisions. Further, the contextual mean square deviation (CMSD) model is employed to compute user pairs’ similarity using the obtained adaptive divisions of accessible ratings. The experimental results obtained on the benchmark Movielens-100K and Movielens-1M datasets justify the proposed model’s superiority over the competitive models.
Collaborative filtering (CF) recommendation algorithms are well-known for their outstanding recommendation performances, but previous researches showed that they could cause privacy leakage for users due to k-nearest neighboring (KNN) attacks. Recently, the notion of differential privacy (DP) has been applied to privacy preservation for collaborative filtering recommendation algorithms. However, as far as we know, existing differentially private CF recommendation schemes degraded the recommendation performance (such as recall and precision) to an unacceptable level. In this paper, in order to address the performance degradation problem, we propose a differentially private user-based collaborative filtering recommendation scheme based on k-means clustering (KDPCF). Specifically, to improve the recommendation performance, we first cluster the dataset into categories by k-means clustering and appropriately adjust the size of the target category to which the target user belongs, so that only users in the well-sized target category can be used for recommendations. Then we efficiently select a set of neighbors from the target category at one time by employing only one exponential mechanism instead of the composition of multiple ones, and base on the neighbor set to recommend. We theoretically prove that our scheme achieves differential privacy. Empirically, we use the MovieLens dataset to evaluate our recommendation system. The experimental results demonstrate a significant performance gain compared to existing schemes.
The business objectives of recommenders, such as increasing sales, are aligned with the causal effect of recommendations. Previous recommenders targeting for the causal effect employ the inverse propensity scoring (IPS) in causal inference. However, IPS is prone to suffer from high variance. The matching estimator is another representative method in causal inference field. It does not use propensity and hence free from the above variance problem. In this work, we unify traditional neighborhood recommendation methods with the matching estimator, and develop robust ranking methods for the causal effect of recommendations. Our experiments demonstrate that the proposed methods outperform various baselines in ranking metrics for the causal effect. The results suggest that the proposed methods can achieve more sales and user engagement than previous recommenders.
Recently, embedding techniques have achieved impressive success in recommender systems. However, the embedding techniques are data demanding and suffer from the cold-start problem. Especially, for the cold-start item which only has limited interactions, it is hard to train a reasonable item ID embedding, called cold ID embedding, which is a major challenge for the embedding techniques. The cold item ID embedding has two main problems: (1) A gap is existing between the cold ID embedding and the deep model. (2) Cold ID embedding would be seriously affected by noisy interaction. However, most existing methods do not consider both two issues in the cold-start problem, simultaneously. To address these problems, we adopt two key ideas: (1) Speed up the model fitting for the cold item ID embedding (fast adaptation). (2) Alleviate the influence of noise. Along this line, we propose Meta Scaling and Shifting Networks to generate scaling and shifting functions for each item, respectively. The scaling function can directly transform cold item ID embeddings into warm feature space which can fit the model better, and the shifting function is able to produce stable embeddings from the noisy embeddings. With the two meta networks, we propose Meta Warm Up Framework (MWUF) which learns to warm up cold ID embeddings. Moreover, MWUF is a general framework that can be applied upon various existing deep recommendation models. The proposed model is evaluated on three popular benchmarks, including both recommendation and advertising datasets. The evaluation results demonstrate its superior performance and compatibility.
Graph neural networks (GNN) recently achieved huge success in collaborative filtering (CF) due to the useful graph structure information. However, users will continuously interact with items, which causes the user-item interaction graphs to change over time and well-trained GNN models to be out-of-date soon. Naive solutions such as periodic retraining lose important temporal information and are computationally expensive. Recent works that leverage recurrent neural networks to keep GNN up-to-date may suffer from the "catastrophic forgetting'' issue, and experience a cold start with new users and items. To this end, we propose the incremental graph convolutional network (IGCN) --- a pure graph convolutional network (GCN) based method to update GNN models when new user-item interactions are available. IGCN consists of two main components: 1) a historical feature generation layer, which generates the initial user/item embedding via model agnostic meta-learning and ensures good initial states and fast model adaptation; 2) a temporal feature learning layer, which first aggregates the features from local neighborhood to update the embedding of each user/item within each subgraph via graph convolutional network and then fuses the user/item embeddings from last subgraph and current subgraph via incremental temporal convolutional network. Experimental studies on real-world datasets show that IGCN can outperform state-of-the-art CF algorithms in sequential recommendation tasks.
Online education platforms play an increasingly important role in mediating the success of individuals’ careers. Therefore, while building overlying content recommendation services, it becomes essential to guarantee that learners are provided with equal recommended learning opportunities, according to the platform principles, context, and pedagogy. Though the importance of ensuring equality of learning opportunities has been well investigated in traditional institutions, how this equality can be operationalized in online learning ecosystems through recommender systems is still under-explored. In this paper, we shape a blueprint of the decisions and processes to be considered in the context of equality of recommended learning opportunities, based on principles that need to be empirically-validated (no evaluation with live learners has been performed). To this end, we first provide a formalization of educational principles that model recommendations’ learning properties, and a novel fairness metric that combines them to monitor the equality of recommended learning opportunities among learners. Then, we envision a scenario wherein an educational platform should be arranged in such a way that the generated recommendations meet each principle to a certain degree for all learners, constrained to their individual preferences. Under this view, we explore the learning opportunities provided by recommender systems in a course platform, uncovering systematic inequalities. To reduce this effect, we propose a novel post-processing approach that balances personalization and equality of recommended opportunities. Experiments show that our approach leads to higher equality, with a negligible loss in personalization. This paper provides a theoretical foundation for future studies of learners’ preferences and limits concerning the equality of recommended learning opportunities.
This paper comprehensively studies a content-centric mobile network based on a preference learning framework, where each mobile user is equipped with a finite-size cache. We consider a practical scenario where each user requests a content file according to its own preferences, which is motivated by the existence of heterogeneity in file preferences among different users. Under our model, we consider a single-hop-based device-to-device (D2D) content delivery protocol and characterize the average hit ratio for the following two file preference cases: the personalized file preferences and the common file preferences. By assuming that the model parameters such as user activity levels, user file preferences, and file popularity are unknown and thus need to be inferred, we present a collaborative filtering (CF)-based approach to learn these parameters. Then, we reformulate the hit ratio maximization problems into a submodular function maximization and propose two computationally efficient algorithms including a greedy approach to efficiently solve the cache allocation problems. We analyze the computational complexity of each algorithm. Moreover, we analyze the corresponding level of the approximation that our greedy algorithm can achieve compared to the optimal solution. Using a real-world dataset, we demonstrate that the proposed framework employing the personalized file preferences brings substantial gains over its counterpart for various system parameters.
Numerous accessibility features have been developed and included in consumer operating systems to provide people with a variety of disabilities additional ways to access computing devices. Unfortunately, many users, especially older adults who are more likely to experience ability changes, are not aware of these features or do not know which combination to use. In this paper, we first quantify this problem via a survey with 100 participants, demonstrating that very few people are aware of built-in accessibility features on their phones. These observations led us to investigate accessibility recommendation as a way to increase awareness and adoption. We developed four prototype recommenders that span different accessibility categories, which we used to collect insights from 20 older adults. Our work demonstrates the need to increase awareness of existing accessibility features on mobile devices, and shows that automated recommendation could help people find beneficial accessibility features.
Advertising expenditures have become the major source of revenue for e-commerce platforms. Providing good advertising experiences for advertisers by reducing their costs of trial and error in discovering the optimal advertising strategies is crucial for the long-term prosperity of online advertising. To achieve this goal, the advertising platform needs to identify the advertiser's optimization objectives, and then recommend the corresponding strategies to fulfill the objectives. In this work, we first deploy a prototype of strategy recommender system on Taobao display advertising platform, which indeed increases the advertisers' performance and the platform's revenue, indicating the effectiveness of strategy recommendation for online advertising. We further augment this prototype system by explicitly learning the advertisers' preferences over various advertising performance indicators and then optimization objectives through their adoptions of different recommending advertising strategies. We use contextual bandit algorithms to efficiently learn the advertisers' preferences and maximize the recommendation adoption, simultaneously. Simulation experiments based on Taobao online bidding data show that the designed algorithms can effectively optimize the strategy adoption rate of advertisers.
Due to the huge expand in global markets and financial transactions, the importance of E-commerce has grown significantly, so to achieve fully functioning, scalable, reliable, efficient, secure, and user-friendly E-commerce system, Adequate system analysis and design procedures are essential. On the other hand The internet vast growing has totally altered the way most companies work. The Internet has created a means for e-Commerce the internet has created a way to provide a unique avenue for companies and customers to sell and buy goods and services. When creating an e-commerce website, there are several goals that must be taken into account, one of them is how to Increase the site’s efficiency to ensure customer turnout and thus achieve the required material profits. There are several methods that are followed to increase the efficiency of the site. One of these methods is the recommender system. This paper produces a study overview of the value of recommended systems and thoroughly analyzed Collaborative Recommender System (CF) techniques with its techniques., which presents proposals to customers according to their interests, making it easier for the customer to search and thus choose the goods that suit him.
Abstract Easy accessibility of data and functions are the main advantages to develop mashups from abundant sources of Web APIs. However, it simultaneously brings difficulties to choose suitable APIs for a mashup. Existing probabilistic matrix factorization (PMF) recommender systems can effectively exploit the latent features of the invocations with the same weight but not all features are equally significant and predictive, and the useless features may bring noises to the model. In this work, we propose the Attentional PMF Model (AMF), which leverages a neural attentional network to learn the significance of latent features. We then inject the attentional scores and the mashup-API context similarity into the matrix factorization structure for training. Furthermore, our model exploits the relationship between APIs from both their context and co-invocation history as regularization terms to improve its prediction performance. Our experiments are evaluated on ProgrammableWeb. The results show that our model outperforms some state-of-art recommender systems in mashup service applications.
Representation learning is the keystone for collaborative filtering. The learned representations should reflect both explicit factors that are revealed by extrinsic attributes such as movies' genres, books' authors, and implicit factors that are implicated in the collaborative signal. Existing methods fail to decompose these two types of factors, making it difficult to infer the deep motivations behind user behaviors, and thus suffer from sub-optimal solutions. In this paper, we propose Decomposed Collaborative Filtering (DCF) to address the above problems. For the explicit representation learning, we devise a user-specific relation aggregator to aggregate the most important attributes. For the implicit part, we propose Decomposed Graph Convolutional Network (DGCN), which decomposes users and items into multiple factor-level representations, then utilizes factor-level attention and attentive relation aggregation to model implicit factors behind collaborative signals in fine-grained level. Moreover, to reflect more diverse implicit factors, we augment the model with disagreement regularization. We conduct experiments on three public accessible datasets and the results demonstrate the significant improvement of our method over several state-of-the-art baselines. Further studies verify the efficacy and interpretability benefits bought from the fine-grained implicit relation modeling. Our Code is available on https://github.com/cmaxhao/DCF.
Although recommendation systems are the most powerful tool to help people choose items, a higher recommendation accuracy is required to satisfy the needs of the people. Motivated by this requirement, this study proposes a novel collaborative filtering (CF) algorithm, which is the underlying technology of a recommendation system. It filters items for a target user based on the reactions of similar users. Cluster analysis helps detect similar users by grouping a set of users such that users in the same group are more similar to each other than to those in other groups. However, in most representative CF algorithms such as GroupLens algorithm, users are considered as spherical data, and as categorical multivariate data in the clustering phase of a previous study. This study overcomes this logic gap by proposing a novel CF method using fuzzy clustering for spherical data based on q-divergence as both the clustering phase and the GroupLens algorithm consistently deal with users as spherical data. Experiments were conducted on six real datasets—BookCrossing, Epinions, Jester, LibimSeTi, MovieLens, and SUSHI, to compare the performance of the proposed method with GroupLens and the method using fuzzy clustering for categorical multivariate data based on q-divergence, which are conventional methods, where the performance is measured by the area under the receiver operating curve. The results of the experiments indicate that the proposed algorithm outperforms the others in terms of recommendation accuracy.
Point of interest (POI) recommendation is a fundamental task in location-based social networks (LBSN). The increasing proliferation of LBSNs brings about considerable amounts of user-generated check-in data. Such data can significantly contribute to understanding user behaviors, based on which personalized recommendations can be efficiently derived. Spatial and temporal effects are crucial factors in the user’s decision-making for choosing a POI to visit. Most existing methods treat them as two independent features and cannot accurately capture users’ interests. We argue that spatial and temporal effects should be analyzed simultaneously in POI recommendations. To this end, we propose a S patioT emporal heterogeneous information Network (HIN)-based PO I RE commendation model (STORE) to model various heterogeneous context features, e.g., the joint spatiotemporal effects, types of POI, and social relations. Specifically, we defined the spatiotemporal effects entity (St) in HIN to model the joint spatiotemporal effects. Instead of modeling the traditional two-way interaction , we further design a four-way neural interaction model . In this way, our model can effectively mine and extract useful information from the meta-path-based context and spatiotemporal effects, thereby improving recommendation performance. We conduct extensive experiments on two real-world datasets, and the results demonstrate that the STORE model outperforms the best baseline by about 12% in NDCG@5 and 11% in Rec@5.
The design of algorithms that generate personalized ranked item lists is a central topic of research in the field of recommender systems. In the past few years, in particular, approaches based on deep learning (neural) techniques have become dominant in the literature. For all of them, substantial progress over the state-of-the-art is claimed. However, indications exist of certain problems in today’s research practice, e.g., with respect to the choice and optimization of the baselines used for comparison, raising questions about the published claims. To obtain a better understanding of the actual progress, we have compared recent results in the area of neural recommendation approaches based on collaborative filtering against a consistent set of existing simple baselines. The worrying outcome of the analysis of these recent works—all were published at prestigious scientific conferences between 2015 and 2018—is that 11 of the 12 reproducible neural approaches can be outperformed by conceptually simple methods, e.g., based on the nearest-neighbor heuristic or linear models. None of the computationally complex neural methods was actually consistently better than already existing learning-based techniques, e.g., using matrix factorization or linear models. In our analysis, we discuss common issues in today’s research practice, which, despite the many papers that are published on the topic, have apparently led the field to a certain level of stagnation.1
